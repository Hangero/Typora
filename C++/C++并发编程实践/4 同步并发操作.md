# 同步并发操作

**本章主要内容**

- 等待事件
- 带有期望的等待一次性事件
- 在限定时间内等待
- 使用同步操作简化代码

在第一个线程完成前，可能需要等待另一个线程执行完成。通常情况下，线程会等待一个特定事件的发生，或者等待某一条件达成(为true)。这可能需要定期检查“任务完成”标识，或将类似的东西放到共享数据中，但这与理想情况还是差很多。像这种情况就需要在线程中进行同步，C++标准库提供了一些工具可用于同步操作，形式上表现为条件变量(*condition variables*)和期望(*futures*)。

## 等待一个事件或其他条件

当一个线程等待另一个线程完成任务时，它会有很多选择。第一，它可以持续的检查共享数据标志(用于做保护工作的互斥量)，直到另一线程完成工作时对这个标志进行重设。不过，就是一种浪费：线程消耗宝贵的执行时间持续的检查对应标志，并且当互斥量被等待线程上锁后，其他线程就没有办法获取锁，这样线程就会持续等待。因为以上方式对等待线程限制资源，并且在完成时阻碍对标识的设置。等待的线程会等待更长的时间，这些线程也在消耗着系统资源。

第二个选择是在等待线程在检查间隙，使用`std::this_thread::sleep_for()`进行周期性的间歇(详见4.3节)：

```cpp
bool flag;
std::mutex m;

void wait_for_flag()
{
  std::unique_lock<std::mutex> lk(m);
  while(!flag)
  {
    lk.unlock();  // 1 解锁互斥量
    std::this_thread::sleep_for(std::chrono::milliseconds(100));  // 2 休眠100ms
    lk.lock();   // 3 再锁互斥量
  }
}
```

在这个循环中，在休眠前②，函数对互斥量进行解锁①，并且在休眠结束后再对互斥量进行上锁，所以另外的线程就有机会获取锁并设置标识。

这个实现就进步很多，因为当线程休眠时，线程没有浪费执行时间，但是很难确定正确的休眠时间。太短的休眠和没有休眠一样，都会浪费执行时间；太长的休眠时间，可能会让任务等待线程醒来。休眠时间过长是很少见的情况，因为这会直接影响到程序的行为，当在高节奏游戏(fast-paced game)中，它意味着丢帧，或在一个实时应用中超越了一个时间片。

第三个选择(也是优先的选择)是，使用C++标准库提供的工具去等待事件的发生。通过另一线程触发等待事件的机制是最基本的唤醒方式(例如：流水线上存在额外的任务时)，这种机制就称为“条件变量”(condition variable)。从概念上来说，一个条件变量会与多个事件或其他条件相关，并且一个或多个线程会等待条件的达成。当某些线程被终止时，为了唤醒等待线程(允许等待线程继续执行)终止的线程将会向等待着的线程广播“条件达成”的信息。

### 等待条件达成

C++标准库对条件变量有两套实现：`std::condition_variable`和`std::condition_variable_any`。这两个实现都包含在`<condition_variable>`头文件的声明中。两者都需要与一个互斥量一起才能工作(互斥量是为了同步)；前者仅限于与`std::mutex`一起工作，而后者可以和任何满足最低标准的互斥量一起工作，从而加上了*_any*的后缀。`std::condition_variable`一般作为首选的类型，当对灵活性有硬性要求时，我们才会去考虑`std::condition_variable_any`。

所以，如何使用`std::condition_variable`去处理之前提到的情况——当有数据需要处理时，如何唤醒休眠中的线程对其进行处理？以下清单展示了一种使用条件变量做唤醒的方式。

> 清单4.1 使用`std::condition_variable`处理数据等待
>
> ```cpp
> std::mutex mut;
> std::queue<data_chunk> data_queue;  // 1
> std::condition_variable data_cond;
> 
> void data_preparation_thread()
> {
>   while(more_data_to_prepare())
>   {
>     data_chunk const data=prepare_data();
>     std::lock_guard<std::mutex> lk(mut);
>     data_queue.push(data);  // 2
>     data_cond.notify_one();  // 3
>   }
> }
> 
> void data_processing_thread()
> {
>   while(true)
>   {
>     std::unique_lock<std::mutex> lk(mut);  // 4
>     data_cond.wait(
>          lk,[]{return !data_queue.empty();});  // 5
>     data_chunk data=data_queue.front();
>     data_queue.pop();
>     lk.unlock();  // 6
>     process(data);
>     if(is_last_chunk(data))
>       break;
>   }
> }
> ```
>
> 首先，你拥有一个用来在两个线程之间传递数据的队列①。**当数据准备好时，使用`std::lock_guard`对队列上锁，将准备好的数据压入队列中②，之后线程会对队列中的数据上锁。然后调用`std::condition_variable`的notify_one()成员函数，对等待的线程(如果有等待线程)进行通知③。**
>
> 线程之后会调用`std::condition_variable`的成员函数wait()，传递一个锁和一个lambda函数表达式(作为等待的条件⑤)。wait()会去检查这些条件(通过调用所提供的lambda函数)，当条件满足(lambda函数返回true)时返回。如果条件不满足(lambda函数返回false)，wait()函数将解锁互斥量，并且将这个线程(上段提到的处理数据的线程)置于阻塞或等待状态。当准备数据的线程调用notify_one()通知条件变量时，处理数据的线程从睡眠状态中苏醒，重新获取互斥锁，并且对条件再次检查，在条件满足的情况下，从wait()返回并继续持有锁。当条件不满足时，线程将对互斥量解锁，并且重新开始等待。这就是为什么用`std::unique_lock`而不使用`std::lock_guard`——等待中的线程必须在等待期间解锁互斥量，并在这这之后对互斥量再次上锁，而`std::lock_guard`没有这么灵活。**如果互斥量在线程休眠期间保持锁住状态，准备数据的线程将无法锁住互斥量，也无法添加数据到队列中；同样的，等待线程也永远不会知道条件何时满足。**（没看懂）
>
> 当等待线程重新获取互斥量并检查条件时，如果它并非直接响应另一个线程的通知，这就是所谓的“伪唤醒”(*spurious wakeup*)。因为任何伪唤醒的数量和频率都是不确定的，这里不建议使用一个有副作用的函数做条件检查。当你这样做了，就必须做好多次产生副作用的心理准备。



### 使用条件变量构建安全队列

……



## 使用期望等待一次性事件

> 假设你乘飞机去国外度假。当你到达机场，并且办理完各种登机手续后，你还需要等待机场广播通知你登机，可能要等很多个小时。你可能会在候机室里面找一些事情来打发时间，比如：读书，上网，或者来一杯价格不菲的机场咖啡，不过从根本上来说你就在等待一件事情：机场广播能够登机的时间。给定的飞机班次再之后没有可参考性；当你在再次度假的时候，你可能会等待另一班飞机。

C++标准库模型将这种一次性事件称为“期望” (*future*)。**当一个线程需要等待一个特定的一次性事件时，在某种程度上来说它就需要知道这个事件在未来的表现形式。**之后，这个线程会周期性(较短的周期)的等待或检查，事件是否触发(检查信息板)；在检查期间也会执行其他任务(品尝昂贵的咖啡)。另外，在等待任务期间它可以先执行另外一些任务，直到对应的任务触发，而后等待期望的状态会变为“就绪”(*ready*)。一个“期望”可能是数据相关的(比如，你的登机口编号)，也可能不是。当事件发生时(并且期望状态为就绪)，这个“期望”就不能被重置。

在C++标准库中，有两种“期望”，使用两种类型模板实现，声明在头文件中: 唯一期望(*unique futures*)(`std::future<>`)和共享期望(*shared futures*)(`std::shared_future<>`)。这是仿照`std::unique_ptr`和`std::shared_ptr`。

**`std::future`的实例只能与一个指定事件相关联，而`std::shared_future`的实例就能关联多个事件。**后者的实现中，所有实例会在同时变为就绪状态，并且他们可以访问与事件相关的任何数据。这种数据关联与模板有关，比如`std::unique_ptr` 和`std::shared_ptr`的模板参数就是相关联的数据类型。在与数据无关的地方，可以使用`std::future<void>`与`std::shared_future<void>`的特化模板。虽然，我希望用于线程间的通讯，但是**“期望”对象本身并不提供同步访问。当多个线程需要访问一个独立“期望”对象时，他们必须使用互斥量或类似同步机制对访问进行保护**，如在第3章提到的那样。不过，在你将要阅读到的4.2.5节中，多个线程会对一个`std::shared_future<>`实例的副本进行访问，而不需要期望同步，即使他们是同一个异步结果。



### 带返回值的后台任务

假设，你有一个需要长时间的运算，你需要其能计算出一个有效的值，但是你现在并不迫切需要这个值。可能你已经找到了生命、宇宙，以及万物的答案，就像道格拉斯·亚当斯[1]一样。你可以启动一个新线程来执行这个计算，但是这就意味着你必须关注如何传回计算的结果，因为`std::thread`并不提供直接接收返回值的机制。这里就需要`std::async`函数模板(也是在头文件中声明的)了。

当任务的结果你不着急要时，你可以使用`std::async`启动一个异步任务。与`std::thread`对象等待运行方式的不同，`std::async`会返回一个`std::future`对象，这个对象持有最终计算出来的结果。当你需要这个值时，你只需要调用这个对象的get()成员函数；并且直到“期望”状态为就绪的情况下，线程才会阻塞；之后，返回计算结果。

> 清单4.6 使用`std::future`从异步任务中获取返回值
>
> ```cpp
> #include <future>
> #include <iostream>
> 
> int find_the_answer_to_ltuae();
> void do_other_stuff();
> int main()
> {
>   std::future<int> the_answer=std::async(find_the_answer_to_ltuae);
>   do_other_stuff();
>   std::cout<<"The answer is "<<the_answer.get()<<std::endl;
> }
> ```

与`std::thread` 做的方式一样，`std::async`允许你通过添加额外的调用参数，向函数传递额外的参数。当第一个参数是一个指向成员函数的指针，第二个参数提供有这个函数成员类的具体对象(不是直接的，就是通过指针，还可以包装在`std::ref`中)，剩余的参数可作为成员函数的参数传入。否则，第二个和随后的参数将作为函数的参数，或作为指定可调用对象的第一个参数。就如`std::thread`，当参数为右值(*rvalues*)时，拷贝操作将使用移动的方式转移原始数据。这就允许使用“只移动”类型作为函数对象和参数。

> 清单4.7 使用`std::async`向函数传递参数
>
> ```cpp
> #include <string>
> #include <future>
> struct X
> {
>   void foo(int,std::string const&);
>   std::string bar(std::string const&);
> };
> X x;
> auto f1=std::async(&X::foo,&x,42,"hello");  // 调用p->foo(42, "hello")，p是指向x的指针
> auto f2=std::async(&X::bar,x,"goodbye");  // 调用tmpx.bar("goodbye")， tmpx是x的拷贝副本
> struct Y
> {
>   double operator()(double);
> };
> Y y;
> auto f3=std::async(Y(),3.141);  // 调用tmpy(3.141)，tmpy通过Y的移动构造函数得到
> auto f4=std::async(std::ref(y),2.718);  // 调用y(2.718)
> X baz(X&);
> std::async(baz,std::ref(x));  // 调用baz(x)
> class move_only
> {
> public:
>   move_only();
>   move_only(move_only&&)
>   move_only(move_only const&) = delete;
>   move_only& operator=(move_only&&);
>   move_only& operator=(move_only const&) = delete;
> 
>   void operator()();
> };
> auto f5=std::async(move_only());  // 调用tmp()，tmp是通过std::move(move_only())构造得到
> ```



在默认情况下，这取决于`std::async`是否启动一个线程，或是否在期望等待时同步任务。在大多数情况下(估计这就是你想要的结果)，但是你也可以在函数调用之前，向`std::async`传递一个额外参数。这个参数的类型是`std::launch`，还可以是`std::launch::defered`，用来表明函数调用被延迟到wait()或get()函数调用时才执行，`std::launch::async` 表明函数必须在其所在的独立线程上执行，`std::launch::deferred | std::launch::async`表明实现可以选择这两种方式的一种。最后一个选项是默认的。当函数调用被延迟，它可能不会在运行了。如下所示：

```cpp
auto f6=std::async(std::launch::async,Y(),1.2);  // 在新线程上执行
auto f7=std::async(std::launch::deferred,baz,std::ref(x));  // 在wait()或get()调用时执行
auto f8=std::async(
              std::launch::deferred | std::launch::async,
              baz,std::ref(x));  // 实现选择执行方式
auto f9=std::async(baz,std::ref(x));
f7.wait();  //  调用延迟函数
```

**使用`std::async`会让分割算法到各个任务中变的容易，这样程序就能并发的执行了。**不过，这不是让一个`std::future`与一个任务实例相关联的唯一方式；你也可以将任务包装入一个`std::packaged_task<>`实例中，或通过编写代码的方式，使用`std::promise<>`类型模板显示设置值。与`std::promise<>`对比，`std::packaged_task<>`具有更高层的抽象，所以我们从“高抽象”的模板说起。



### 任务与期望

`std::packaged_task<>`对一个函数或可调用对象，绑定一个期望。**当`std::packaged_task<>` 对象被调用，它就会调用相关函数或可调用对象，将期望状态置为就绪，返回值也会被存储为相关数据。**这可以用在构建线程池的建筑块(可见第9章)，或用于其他任务的管理，比如在任务所在线程上运行任务，或将它们顺序的运行在一个特殊的后台线程上。**当一个粒度较大的操作可以被分解为独立的子任务时，其中每个子任务就可以包含在一个`std::packaged_task<>`实例中，之后这个实例将传递到任务调度器或线程池中。这就是对任务的细节进行抽象了；调度器仅处理`std::packaged_task<>`实例，要比处理独立的函数高效的多。**

`std::packaged_task<>`的模板参数是一个函数签名，比如void()就是一个没有参数也没有返回值的函数，或int(std::string&, double*)就是有一个非const引用的`std::string`和一个指向double类型的指针，并且返回类型是int。**当你构造出一个`std::packaged_task<>`实例时，你必须传入一个函数或可调用对象，这个函数或可调用的对象需要能接收指定的参数和返回可转换为指定返回类型的值。**类型可以不完全匹配；你可以用一个int类型的参数和返回一个float类型的函数，来构建`std::packaged_task<double(double)>`的实例，因为在这里，类型可以隐式转换。

指定函数签名的返回类型可以用来标识，从get_future()返回的`std::future<>`的类型，不过函数签名的参数列表，可用来指定“打包任务”的函数调用操作符。例如，局部类定义`std::packaged_task<std::string(std::vector<char>*,int)>`将在下面的代码清单中使用。

> 清单4.8 `std::packaged_task<>`的特化——局部类定义
>
> ```cpp
> template<>
> class packaged_task<std::string(std::vector<char>*,int)>
> {
> public:
>   template<typename Callable>
>   explicit packaged_task(Callable&& f);
>   std::future<std::string> get_future();
>   void operator()(std::vector<char>*,int);
> };
> ```

这里的`std::packaged_task`对象是一个可调用对象，并且它可以包含在一个`std::function`对象中，**传递到`std::thread`对象中，就可作为线程函数；传递另一个函数中，就作为可调用对象，或可以直接进行调用。当`std::packaged_task`作为一个函数调用时，可为函数调用操作符提供所需的参数，**并且返回值作为异步结果存储在`std::future`，可通过get_future()获取。你可以把一个任务包含入`std::packaged_task`，并且在检索期望之前，需要将`std::packaged_task`对象传入，以便调用时能及时的找到。

当你需要异步任务的返回值时，你可以等待期望的状态变为“就绪”。

### 线程间传递任务

很多图形架构需要特定的线程去更新界面，所以当一个线程需要界面的更新时，它需要发出一条信息给正确的线程，让特定的线程来做界面更新。`std::packaged_task`提供了完成这种功能的一种方法，且不需要发送一条自定义信息给图形界面相关线程。下面来看看代码。

> 清单4.9 使用`std::packaged_task`执行一个图形界面线程
>
> ```cpp
> #include <deque>
> #include <mutex>
> #include <future>
> #include <thread>
> #include <utility>
> 
> std::mutex m;
> std::deque<std::packaged_task<void()> > tasks;
> 
> bool gui_shutdown_message_received();
> void get_and_process_gui_message();
> 
> void gui_thread()  // 1
> {
>   while(!gui_shutdown_message_received())  // 2
>   {
>     get_and_process_gui_message();  // 3
>     std::packaged_task<void()> task;
>     {
>       std::lock_guard<std::mutex> lk(m);
>       if(tasks.empty())  // 4
>         continue;
>       task=std::move(tasks.front());  // 5
>       tasks.pop_front();
>     }
>     task();  // 6
>   }
> }
> 
> std::thread gui_bg_thread(gui_thread);
> 
> template<typename Func>
> std::future<void> post_task_for_gui_thread(Func f)
> {
>   std::packaged_task<void()> task(f);  // 7
>   std::future<void> res=task.get_future();  // 8
>   std::lock_guard<std::mutex> lk(m);  // 9
>   tasks.push_back(std::move(task));  // 10
>   return res;
> }
> ```
>
> 这段代码十分简单：图形界面线程①循环直到收到一条关闭图形界面的信息后关闭②，进行轮询界面消息处理③，例如用户点击，和执行在队列中的任务。当队列中没有任务④，它将再次循环；除非，他能在队列中提取出一个任务⑤，然后释放队列上的锁，并且执行任务⑥。这里，“期望”与任务相关，当任务执行完成时，其状态会被置为“就绪”状态。
>
> 将一个任务传入队列，也很简单：提供的函数⑦可以提供一个打包好的任务，可以通过这个任务⑧调用get_future()成员函数获取“期望”对象，并且在任务被推入列表⑨之前，“期望”将返回调用函数⑩。当需要知道线程执行完任务时，向图形界面线程发布消息的代码，会等待“期望”改变状态；否则，则会丢弃这个“期望”。



这个例子使用`std::packaged_task<void()>`创建任务，其包含了一个无参数无返回值的函数或可调用对象(如果当这个调用有返回值时，返回值会被丢弃)。这可能是最简单的任务，如你之前所见，`std::packaged_task`也可以用于一些复杂的情况——通过指定一个不同的函数签名作为模板参数，你不仅可以改变其返回类型(因此该类型的数据会存在期望相关的状态中)，而且也可以改变函数操作符的参数类型。这个例子可以简单的扩展成允许任务运行在图形界面线程上，且接受传参，还有通过`std::future`返回值，而不仅仅是完成一个指标。

这些任务能作为一个简单的函数调用来表达吗？还有，这些任务的结果能从很多地方得到吗？这些情况可以使用第三种方法创建“期望”来解决：使用`std::promise`对值进行显示设置。

### 使用`std::promises`

**考虑一个线程处理多个连接事件，来自不同的端口连接的数据包基本上是以乱序方式进行处理的；同样的，数据包也将以乱序的方式进入队列。在很多情况下，另一些应用不是等待数据成功的发送，就是等待一批(新的)来自指定网络接口的数据接收成功。**

`std::promise<T>`提供设定值的方式(类型为T)，这个类型会和后面看到的`std::future<T>` 对象相关联。**一对`std::promise/std::future`会为这种方式提供一个可行的机制；在期望上可以阻塞等待线程，同时，提供数据的线程可以使用组合中的“承诺”来对相关值进行设置，以及将“期望”的状态置为“就绪”。**

可以通过get_future()成员函数来获取与一个给定的`std::promise`相关的`std::future`对象，就像是与`std::packaged_task`相关。当“承诺”的值已经设置完毕(使用set_value()成员函数)，对应“期望”的状态变为“就绪”，并且可用于检索已存储的值。当你在设置值之前销毁`std::promise`，将会存储一个异常。

清单4.10中，是**单线程处理多接口的实现**，如同我们所说的那样。在这个例子中，**你可以使用一对`std::promise<bool>/std::future<bool>`找出一块传出成功的数据块；与“期望”相关值只是一个简单的“成功/失败”标识。**对于传入包，与“期望”相关的数据就是数据包的有效负载。

> 清单4.10 使用“承诺”解决单线程多连接问题
>
> ```cpp
> #include <future>
> 
> void process_connections(connection_set& connections)
> {
>   while(!done(connections))  // 1
>   {
>     for(connection_iterator  // 2
>             connection=connections.begin(),end=connections.end();
>           connection!=end;
>           ++connection)
>     {
>       if(connection->has_incoming_data())  // 3
>       {
>         data_packet data=connection->incoming();
>         std::promise<payload_type>& p=
>             connection->get_promise(data.id);  // 4
>         p.set_value(data.payload);
>       }
>       if(connection->has_outgoing_data())  // 5
>       {
>         outgoing_packet data=
>             connection->top_of_outgoing_queue();
>         connection->send(data.payload);
>         data.promise.set_value(true);  // 6
>       }
>     }
>   }
> }
> ```
>
> 函数process_connections()中，直到done()返回true①为止。每一次循环，程序都会依次的检查每一个连接②，检索是否有数据③或正在发送已入队的传出数据⑤。这里假设输入数据包是具有ID和有效负载的(有实际的数在其中)。一个ID映射到一个`std::promise`(可能是在相关容器中进行的依次查找)④，并且值是设置在包的有效负载中的。对于传出包，包是从传出队列中进行检索的，实际上从接口直接发送出去。当发送完成，与传出数据相关的“承诺”将置为true，来表明传输成功⑥。这是否能映射到实际网络协议上，取决于网络所用协议；这里的“承诺/期望”组合方式可能会在特殊的情况下无法工作，但是它与一些操作系统支持的异步输入/输出结构类似。

使用`std::packaged_task`或`std::promise`，就会带来一些不必要的限制(在所有工作都正常的情况下)。因此，C++标准库提供了一种在以上情况下清理异常的方法，并且允许他们将异常存储为相关结果的一部分。

### 为"期望"存储“异常”

看完下面短小的代码段，思考一下，当你传递-1到square_root()中时，它将抛出一个异常，并且这个异常将会被调用者看到：

```cpp
double square_root(double x)
{
  if(x<0)
  {
    throw std::out_of_range(“x<0”);
  }
  return sqrt(x);
}
```

假设调用square_root()函数不是当前线程，

```cpp
double y=square_root(-1);
```

你将这样的调用改为异步调用：

```cpp
std::future<double> f=std::async(square_root,-1);
double y=f.get();
```

如果行为是完全相同的时候，其结果是理想的；在任何情况下，y获得函数调用的结果，当线程调用f.get()时，就能再看到异常了，即使在一个单线程例子中。

好吧，事实的确如此：函数作为`std::async`的一部分时，当在调用时抛出一个异常，那么这个异常就会存储到“期望”的结果数据中，之后“期望”的状态被置为“就绪”，之后调用get()会抛出这个存储的异常。(注意：标准级别没有指定重新抛出的这个异常是原始的异常对象，还是一个拷贝；不同的编译器和库将会在这方面做出不同的选择)。当你将函数打包入`std::packaged_task`任务包中后，在这个任务被调用时，同样的事情也会发生；当打包函数抛出一个异常，这个异常将被存储在“期望”的结果中，准备在调用get()再次抛出。

当然，通过函数的显式调用，`std::promise`也能提供同样的功能。**当你希望存入的是一个异常而非一个数值时，你就需要调用set_exception()成员函数，而非set_value()。这通常是用在一个catch块中，并作为算法的一部分，为了捕获异常，使用异常填充“承诺”：**

```cpp
extern std::promise<double> some_promise;
try
{
  some_promise.set_value(calculate_value());
}
catch(...)
{
  some_promise.set_exception(std::current_exception());
}
```

这里使用了`std::current_exception()`来检索抛出的异常；可用`std::copy_exception()`作为一个替换方案，`std::copy_exception()`会直接存储一个新的异常而不抛出：

```cpp
some_promise.set_exception(std::copy_exception(std::logic_error("foo ")));
```

这就比使用try/catch块更加清晰，**当异常类型是已知的，它就应该优先被使用；不是因为代码实现简单，而是它给编译器提供了极大的代码优化空间。**

**另一种向“期望”中存储异常的方式是，在没有调用“承诺”上的任何设置函数前，或正在调用包装好的任务时，销毁与`std::promise`或`std::packaged_task`相关的“期望”对象。**在这任何情况下，当“期望”的状态还不是“就绪”时，调用`std::promise`或`std::packaged_task`的析构函数，将会存储一个与`std::future_errc::broken_promise`错误状态相关的`std::future_error`异常；通过创建一个“期望”，你可以构造一个“承诺”为其提供值或异常；你可以通过销毁值和异常源，去违背“承诺”。在这种情况下，编译器没有在“期望”中存储任何东西，等待线程可能会永远的等下去。

直到现在，所有例子都在用`std::future`。不过，`std::future`也有局限性，在很多线程在等待的时候，只有一个线程能获取等待结果。**当多个线程需要等待相同的事件的结果，你就需要使用`std::shared_future`来替代`std::future`了。**



### 多个线程的等待

虽然`std::future`可以处理所有在线程间数据转移的必要同步，但是**调用某一特殊`std::future`对象的成员函数，就会让这个线程的数据和其他线程的数据不同步。**当多线程在没有额外同步的情况下，访问一个独立的`std::future`对象时，就会有数据竞争和未定义的行为。这是因为：`std::future`模型独享同步结果的所有权，并且通过调用get()函数，一次性的获取数据，这就让并发访问变的毫无意义——只有一个线程可以获取结果值，**因为在第一次调用get()后，就没有值可以再获取了。**

> **`std::future`是只移动的，所以其所有权可以在不同的实例中互相传递，但是只有一个实例可以获得特定的同步结果**

`std::shared_future`可以来帮你解决。`std::shared_future`实例是可拷贝的，所以多个对象可以引用同一关联“期望”的结果。

**在每一个`std::shared_future`的独立对象上成员函数调用返回的结果还是不同步的**，所以为了在多个线程访问一个独立对象时，避免数据竞争，**必须使用锁来对访问进行保护。**优先使用的办法：为了替代只有一个拷贝对象的情况，**可以让每个线程都拥有自己对应的拷贝对象。这样，当每个线程都通过自己拥有的`std::shared_future`对象获取结果，那么多个线程访问共享同步结果就是安全的。**

<img src="/home/suyu/.config/Typora/typora-user-images/image-20230110003300308.png" alt="image-20230110003300308" style="zoom: 67%;" />

`std::shared_future`的实例同步`std::future`实例的状态。当`std::future`对象没有与其他对象共享同步状态所有权，那么所有权必须使用`std::move`将所有权传递到`std::shared_future`，其默认构造函数如下：

```cpp
std::promise<int> p;
std::future<int> f(p.get_future());
assert(f.valid());  // 1 "期望" f 是合法的
std::shared_future<int> sf(std::move(f));
assert(!f.valid());  // 2 "期望" f 现在是不合法的
assert(sf.valid());  // 3 sf 现在是合法的
```

这里，“期望”f开始是合法的①，因为它引用的是“承诺”p的同步状态，但是在转移sf的状态后，f就不合法了②，而sf就是合法的了③。

如其他可移动对象一样，转移所有权是对右值的隐式操作，所以你可以通过`std::promise`对象的成员函数get_future()的返回值，直接构造一个`std::shared_future`对象，例如：

```cpp
std::promise<std::string> p;
std::shared_future<std::string> sf(p.get_future());  // 1 隐式转移所有权
```

这里转移所有权是隐式的；用一个右值构造`std::shared_future<>`，得到`std::future<std::string>`类型的实例①。

`std::future`的这种特性，可促进`std::shared_future`的使用，容器可以自动的对类型进行推断，从而初始化这个类型的变量(详见附录A，A.6节)。`std::future`有一个share()成员函数，可用来创建新的`std::shared_future` ，并且可以直接转移“期望”的所有权。这样也就能保存很多类型，并且使得代码易于修改：

```cpp
std::promise< std::map< SomeIndexType, SomeDataType, SomeComparator,
     SomeAllocator>::iterator> p;
auto sf=p.get_future().share();
```

在这个例子中，sf的类型推到为`std::shared_future<std::map<SomeIndexType, SomeDataType, SomeComparator, SomeAllocator>::iterator>`，一口气还真的很难念完。当比较器或分配器有所改动，你只需要对“承诺”的类型进行修改即可；“期望”的类型会自动更新，与“承诺”的修改进行匹配。



## 限定等待时间

介绍两种可能是你希望指定的超时方式：一种是“时延”的超时方式，另一种是“绝对”超时方式。第一种方式，需要指定一段时间(例如，30毫秒)；第二种方式，就是指定一个时间点(例如，协调世界时[UTC]17:30:15.045987023，2011年11月30日)。多数等待函数提供变量，对两种超时方式进行处理。处理持续时间的变量以“for”作为后缀，处理绝对时间的变量以"until"作为后缀。

所以，当`std::condition_variable`的两个成员函数wait_for()和wait_until()成员函数分别有两个负载，这两个负载都与wait()成员函数的负载相关——其中一个负载只是等待信号触发，或时间超期，亦或是一个虚假的唤醒，并且醒来时，会检查锁提供的谓词，并且只有在检查为true时才会返回(这时条件变量的条件达成)，或直接而超时。

### 时钟

对于C++标准库来说，时钟就是时间信息源。特别是，时钟是一个类，提供了四种不同的信息：

- 现在时间
- 时间类型
- 时钟节拍
- 通过时钟节拍的分布，判断时钟是否稳定

`std::chrono::system_clock::now()`是将返回系统时钟的当前时间。特定的时间点类型可以通过time_point的数据typedef成员来指定，所以some_clock::now()的类型就是some_clock::time_point。

时钟节拍被指定为1/x(x在不同硬件上有不同的值)秒，这是由时间周期所决定——一个时钟一秒有25个节拍，因此一个周期为`std::ratio<1, 25>`，当一个时钟的时钟节拍每2.5秒一次，周期就可以表示为`std::ratio<5, 2>`。当is_steady静态数据成员为true时，表明这个时钟就是稳定的。

稳定闹钟对于超时的计算很重要，所以C++标准库提供一个稳定时钟`std::chrono::steady_clock`。C++标准库提供的其他时钟可表示为`std::chrono::system_clock`。`std::chrono::high_resolution_clock` 可能是标准库中提供的具有最小节拍周期(因此具有最高的精度[分辨率])的时钟。

### 时延

时延是时间部分最简单的；`std::chrono::duration<>`函数模板能够对时延进行处理(线程库使用到的所有C++时间处理工具，都在`std::chrono`命名空间内)。第一个模板参数是一个类型表示(比如，int，long或double)，第二个模板参数是制定部分，表示每一个单元所用秒数。

> 当几分钟的时间要存在short类型中时，可以写成`std::chrono::duration<short, std::ratio<60, 1>>`，因为60秒是才是1分钟，所以第二个参数写成`std::ratio<60, 1>`。另一方面，当需要将毫秒级计数存在double类型中时，可以写成`std::chrono::duration<double, std::ratio<1, 1000>>`，因为1秒等于1000毫秒。

标准库在`std::chrono`命名空间内，为延时变量提供一系列预定义类型：nanoseconds[纳秒] , microseconds[微秒] , milliseconds[毫秒] , seconds[秒] , minutes[分]和hours[时]。

当不要求截断值的情况下(时转换成秒是没问题，但是秒转换成时就不行)时延的转换是隐式的。显示转换可以由`std::chrono::duration_cast<>`来完成。

```cpp
std::chrono::milliseconds ms(54802);
std::chrono::seconds s=
       std::chrono::duration_cast<std::chrono::seconds>(ms);
```

这里的结果就是截断的，而不是进行了舍入，所以s最后的值将为54。

基于时延的等待可由`std::chrono::duration<>`来完成。例如，你等待一个“期望”状态变为就绪已经35毫秒：

```cpp
std::future<int> f=std::async(some_task);
if(f.wait_for(std::chrono::milliseconds(35))==std::future_status::ready)
  do_something_with(f.get());
```

等待函数会返回一个状态值，来表示等待是超时，还是继续等待。在这种情况下，你可以等待一个“期望”，所以当函数等待超时时，会返回`std::future_status::timeout`；当“期望”状态改变，函数会返回`std::future_status::ready`；当“期望”的任务延迟了，函数会返回`std::future_status::deferred`。基于时延的等待是使用内部库提供的稳定时钟，来进行计时的；所以，即使系统时钟在等待时被调整(向前或向后)，35毫秒的时延在这里意味着，的确耗时35毫秒。

### 时间点

时钟的时间点可以用`std::chrono::time_point<>`的类型模板实例来表示，实例的第一个参数用来指定所要使用的时钟，第二个函数参数用来表示时间的计量单位(特化的`std::chrono::duration<>`)。

你可以通过`std::chrono::time_point<>`实例来加/减时延，来获得一个新的时间点，所以`std::chrono::hight_resolution_clock::now() + std::chrono::nanoseconds(500)`将得到500纳秒后的时间。**当你知道一块代码的最大时延时，这对于计算绝对时间的超时是一个好消息**，当等待时间内，等待函数进行多次调用；或，非等待函数且占用了等待函数时延中的时间。

你也可以减去一个时间点(二者需要共享同一个时钟)。**结果是两个时间点的时间差。这对于代码块的计时是很有用的**，例如：

```cpp
auto start=std::chrono::high_resolution_clock::now();
do_something();
auto stop=std::chrono::high_resolution_clock::now();
std::cout<<”do_something() took “
  <<std::chrono::duration<double,std::chrono::seconds>(stop-start).count()
  <<” seconds”<<std::endl;
```

后缀为_unitl的(等待函数的)变量会使用时间点。通常是使用某些时钟的`::now()`(程序中一个固定的时间点)作为偏移，虽然时间点与系统时钟有关，可以使用`std::chrono::system_clock::to_time_point()` 静态成员函数，在用户可视时间点上进行调度操作。例如，当你有一个对多等待500毫秒的，且与条件变量相关的事件，你可以参考如下代码：

> 清单4.11 等待一个条件变量——有超时功能
>
> ```cpp
> #include <condition_variable>
> #include <mutex>
> #include <chrono>
> 
> std::condition_variable cv;
> bool done;
> std::mutex m;
> 
> bool wait_loop()
> {
>   auto const timeout= std::chrono::steady_clock::now()+
>       std::chrono::milliseconds(500);
>   std::unique_lock<std::mutex> lk(m);
>   while(!done)
>   {
>     if(cv.wait_until(lk,timeout)==std::cv_status::timeout)
>       break;
>   }
>   return done;
> }
> ```
>
> 这种方式是我们推荐的，当你没有什么事情可以等待时，可在一定时限中等待条件变量。在这种方式中，循环的整体长度是有限的。如你在4.1.1节中所见，当使用条件变量(且无事可待)时，你就需要使用循环，这是为了处理假唤醒。当你在循环中使用wait_for()时，你可能在等待了足够长的时间后结束等待(在假唤醒之前)，且下一次等待又开始了。这可能重复很多次，使得等待时间无边无际。

### 具有超时功能的函数

……



## 使用同步操作简化代码

**同步工具的使用在本章称为构建块**，你可以之关注那些需要同步的操作，而非具体使用的机制。当需要为程序的并发时，这是一种可以帮助你简化你的代码的方式，提供更多的函数化(是函数化编程的意思(*functional programming*))方法。**比起在多个线程间直接共享数据，每个任务拥有自己的数据会应该会更好，并且结果可以对其他线程进行广播，这就需要使用“期望”来完成了。**

### 使用“期望”的函数化编程

术语“函数化编程”(*functional programming ( FP )*)引用于一种编程方式，**这种方式中的函数结果只依赖于传入函数的参数，并不依赖外部状态**。当一个函数与数学概念相关时，当你使用相同的函数调用这个函数两次，这两次的结果会完全相同。一个纯粹的函数不会改变任何外部状态，并且这种特性完全限制了函数的返回值。

**很多问题发生在共享数据上。当共享数据没有被修改，那么就不存在条件竞争，并且没有必要使用互斥量去保护共享数据。**

函数化编程的好处，并不限于那些将“纯粹”作为默认方式(范型)的语言。在C++11中这种方式要比C++98简单许多，因为C++11支持lambda表达式(详见附录A，A.6节)，还加入了[Boost](http://zh.wikipedia.org/wiki/Boost_C%2B%2B_Libraries)和[TR1](http://zh.wikipedia.org/wiki/C%2B%2B_Technical_Report_1)中的`std::bind`，以及自动可以自行推断类型的自动变量(详见附录A，A.7节)。“期望”作为拼图的最后一块，它使得函数化编程模式并发化(*FP-style concurrency*)在C++中成为可能；**一个“期望”对象可以在线程间互相传递，并允许其中一个计算结果依赖于另外一个的结果，而非对共享数据的显式访问。**

> 函数化编程模式并发化(*FP-style concurrency*)的四块拼图
>
> - lambda表达式
>
> - `std::bind`
>
> - 自动可以自行推断类型的自动变量`auto`
>
> - “期望”`std::future`

#### 快速排序 FP模式版

为了描述在函数化(PF)并发中使用“期望”，让我们来看看一个简单的实现——快速排序算法。

<img src="/home/suyu/.config/Typora/typora-user-images/image-20230110010622863.png" alt="image-20230110010622863" style="zoom:67%;" />



> 下面清单中的代码是FP-模式的顺序实现，它**需要传入列表，并且返回一个列表**，而非与`std::sort()`做同样的事情。 (译者：**`std::sort()`是无返回值的，因为参数接收的是迭代器，所以其可以对原始列表直进行修改与排序。**可参考[sort()](http://www.cplusplus.com/reference/algorithm/sort/?kw=sort))
>
> 清单4.12 快速排序——顺序实现版
>
> ```cpp
> template<typename T>
> std::list<T> sequential_quick_sort(std::list<T> input)
> {
>   if(input.empty())
>   {
>     return input;
>   }
>   std::list<T> result;
>   result.splice(result.begin(),input,input.begin());  // 1
>   T const& pivot=*result.begin();  // 2
> 
>   auto divide_point=std::partition(input.begin(),input.end(),
>              [&](T const& t){return t<pivot;});  // 3
> 
>   std::list<T> lower_part;
>   lower_part.splice(lower_part.end(),input,input.begin(),
>              divide_point);  // 4
>   auto new_lower(
>              sequential_quick_sort(std::move(lower_part)));  // 5
>   auto new_higher(
>              sequential_quick_sort(std::move(input)));  // 6
> 
>   result.splice(result.end(),new_higher);  // 7
>   result.splice(result.begin(),new_lower);  // 8
>   return result;
> }
> ```
>
> ……
>
> > 为了避免大量的拷贝，是用了`std::partition()`，`std::move()`

#### 快速排序 FP模式线程强化版

因为还是使用函数化模式，所以使用“期望”很容易将其转化为并行的版本，如下面的程序清单所示。其中的操作与前面相同，不同的是它们现在并行运行。****

> 清单4.13 快速排序——“期望”并行版
>
> ```cpp
> template<typename T>
> std::list<T> parallel_quick_sort(std::list<T> input)
> {
>   if(input.empty())
>   {
>     return input;
>   }
>   std::list<T> result;
>   result.splice(result.begin(),input,input.begin());
>   T const& pivot=*result.begin();
> 
>   auto divide_point=std::partition(input.begin(),input.end(),
>                 [&](T const& t){return t<pivot;});
> 
>   std::list<T> lower_part;
>   lower_part.splice(lower_part.end(),input,input.begin(),
>                 divide_point);
> 
>   std::future<std::list<T> > new_lower(  // 1
>                 std::async(&parallel_quick_sort<T>,std::move(lower_part)));
> 
>   auto new_higher(
>                 parallel_quick_sort(std::move(input)));  // 2
> 
>   result.splice(result.end(),new_higher);  // 3
>   result.splice(result.begin(),new_lower.get());  // 4
>   return result;
> }
> ```
>
> 这里最大的变化是，当前线程不对小于“中间”值部分的列表进行排序，使用`std::async()`①在另一线程对其进行排序。大于部分列表，如同之前一样，使用递归的方式进行排序②。通过递归调用parallel_quick_sort()，你就可以利用可用的硬件并发了。`std::async()`会启动一个新线程，这样当你递归三次时，就会有八个线程在运行了。**（注意这里的递归操作）**

比起使用`std::async()`，你可以写一个spawn_task()函数对`std::packaged_task`和`std::thread`做简单的包装，如清单4.14中的代码所示；**你需要为函数结果创建一个`std::packaged_task`对象， 可以从这个对象中获取“期望”，或在线程中执行它，返回“期望”。**其本身并不提供太多的好处(并且事实上会造成大规模的超额任务)，但是它会为转型成一个更复杂的实现铺平道路，将会实现向一个队列添加任务，而后使用线程池的方式来运行它们。我们将在第9章再讨论线程池。**使用`std::async`更适合于当你知道你在干什么，并且要完全控制在线程池中构建或执行过任务的线程。**

> 清单4.14 spawn_task的简单实现
>
> ```cpp
> template<typename F,typename A>
> std::future<std::result_of<F(A&&)>::type>
>    spawn_task(F&& f,A&& a)
> {
>   typedef std::result_of<F(A&&)>::type result_type;
>   std::packaged_task<result_type(A&&)>
>        task(std::move(f)));
>   std::future<result_type> res(task.get_future());
>   std::thread t(std::move(task),std::move(a));
>   t.detach();
>   return res;
> }
> ```

因为避开了共享易变数据，函数化编程可算作是并发编程的范型；并且也是CSP(*Communicating Sequential Processer*[3],通讯顺序进程)的范型，这里线程理论上是完全分开的，也就是没有共享数据，但是有通讯通道允许信息在不同线程间进行传递。这种范型在[MPI](http://www.mpi-forum.org/)(*Message Passing Interface*，消息传递接口)上常用来做C和C++的高性能运算。

### 使用消息传递的同步操作

CSP的概念十分简单：当没有共享数据，每个线程就可以进行独立思考，其行为纯粹基于其所接收到的信息。每个线程就都有一个状态机：当线程收到一条信息，它将会以某种方式更新其状态，并且可能向其他线程发出一条或多条信息，对于消息的处理依赖于线程的初始化状态。

真正通讯顺序处理是没有共享数据的，所有消息都是通过消息队列传递，但是因为C++线程共享一块地址空间，所以达不到真正通讯顺序处理的要求。这里就需要有一些约定了：作为一款应用或者是一个库的作者，我们有责任确保在我们的实现中，线程不存在共享数据。当然，为了线程间的通信，消息队列是必须要共享的，具体的细节可以包含在库中。

<img src="/home/suyu/.config/Typora/typora-user-images/image-20230110012456012.png" alt="image-20230110012456012" style="zoom:67%;" />

​                                                                                                         一台ATM机的状态机模型(简化)

你可以使用一个类实现它，这个类中有一个成员函数可以代表每一个状态。每一个成员函数可以等待从指定集合中传入的信息，以及当他们到达时进行处理，这就有可能触发原始状态向另一个状态的转化。每种不同的信息类型由一个独立的struct表示。

> 清单4.15 ATM逻辑类的简单实现
>
> ```cpp
> struct card_inserted
> {
>   std::string account;
> };
> 
> class atm
> {
>   messaging::receiver incoming;
>   messaging::sender bank;
>   messaging::sender interface_hardware;
>   void (atm::*state)();
> 
>   std::string account;
>   std::string pin;
> 
>   void waiting_for_card()  // 1
>   {
>     interface_hardware.send(display_enter_card());  // 2
>     incoming.wait().  // 3
>       handle<card_inserted>(
>       [&](card_inserted const& msg)  // 4
>       {
>        account=msg.account;
>        pin="";
>        interface_hardware.send(display_enter_pin());
>        state=&atm::getting_pin;
>       }
>     );
>   }
>   void getting_pin();
> public:
>   void run()  // 5
>   {
>     state=&atm::waiting_for_card;  // 6
>     try
>     {
>       for(;;)
>       {
>         (this->*state)();  // 7
>       }
>     }
>     catch(messaging::close_queue const&)
>     {
>     }
>   }
> };
> ```
>
> 这种程序设计的方式被称为**参与者模式**([Actor model](http://zh.wikipedia.org/wiki/參與者模式))——在系统中有很多独立的(运行在一个独立的线程上)参与者，这些参与者会互相发送信息，去执行手头上的任务，并且它们不会共享状态，除非是通过信息直接传入的。
>
> 运行从run()成员函数开始⑤，其将会初始化waiting_for_card⑥的状态，然后反复执行当前状态的成员函数(无论这个状态时怎么样的)⑦。状态函数是简易atm类的成员函数。wait_for_card函数①依旧很简单：它发送一条信息到接口，让终端显示“等待卡片”的信息②，之后就等待传入一条消息进行处理③。这里处理的消息类型只能是card_inserted类的，这里使用一个lambda函数④对其进行处理。当然，你可以传递任何函数或函数对象，去处理函数，但对于一个简单的例子来说，使用lambda表达式是最简单的方式。注意handle()函数调用是连接到wait()函数上的；当收到的信息类型与处理类型不匹配，收到的信息会被丢弃，并且线程继续等待，直到接收到一条类型匹配的消息。





















































