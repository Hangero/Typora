# 高级线程管理

**本章主要内容**

- 线程池
- 处理线程池中任务的依赖关系
- 池中线程如何获取任务
- 中断线程

之前的章节中，我们通过创建`std::thread`对象来对线程进行管理。在一些情况下，这种方式不可行了，因为**需要在线程的整个生命周期中对其进行管理，并根据硬件来确定线程数量，等等。**理想情况是将代码划分为最小块，再并发执行，之后交给处理器和标准库，进行性能优化。

另一种情况是，**当使用多线程来解决某个问题时，在某个条件达成的时候，可以提前结束。可能是因为结果已经确定，或者因为产生错误，亦或是用户执行终止操作。无论是哪种原因，线程都需要发送“请停止”请求，放弃任务，清理，然后尽快停止。**

本章，我们将了解一下**管理线程和任务的机制，从自动管理线程数量和自动管理任务划分开始。**

## 线程池

在大多数系统中，将每个任务指定给某个线程是不切实际的，不过可以利用现有的并发性，进行并发执行。**线程池就提供了这样的功能，提交到线程池中的任务将并发执行，提交的任务将会挂在任务队列上。队列中的每一个任务都会被池中的工作线程所获取，当任务执行完成后，再回到线程池中获取下一个任务。**

创建一个线程池时，会遇到几个关键性的设计问题，比如：可使用的线程数量，高效的任务分配方式，以及是否需要等待一个任务完成。

在本节，我们将看到线程池是如何解决这些问题的，从最简单的线程池开始吧！

### 最简单的线程池

作为最简单的线程池，其拥有固定数量的工作线程(通常工作线程数量与`std::thread::hardware_concurrency()`相同)。当工作需要完成时，可以调用函数将任务挂在任务队列中。每个工作线程都会从任务队列上获取任务，然后执行这个任务，执行完成后再回来获取新的任务。在最简单的线程池中，线程就不需要等待其他线程完成对应任务了。如果需要等待，就需要对同步进行管理。

下面清单中的代码就展示了一个最简单的线程池实现。

> 清单9.1 简单的线程池
>
> ```cpp
> class thread_pool
> {
>   std::atomic_bool done;
>   thread_safe_queue<std::function<void()> > work_queue;  // 1 使用线程安全队列来管理任务队列
>   std::vector<std::thread> threads;  // 2 工作线程
>   join_threads joiner;  // 3 用于汇聚线程
> 
>   void worker_thread()
>   {
>     while(!done)  // 4
>     {
>       std::function<void()> task;
>       if(work_queue.try_pop(task))  // 5
>       {
>         task();  // 6
>       }
>       else
>       {
>         std::this_thread::yield();  // 7
>       }
>     }
>   }
> 
> public:
>   thread_pool():
>     done(false),joiner(threads)
>   {
>     unsigned const thread_count=std::thread::hardware_concurrency();  // 8
> 
>     try
>     {
>       for(unsigned i=0;i<thread_count;++i)
>       {
>         threads.push_back( 
>           std::thread(&thread_pool::worker_thread,this));  // 9
>       }
>     }
>     catch(...)
>     {
>       done=true;  // 10
>       throw;
>     }
>   }
> 
>   ~thread_pool()
>   {
>     done=true;  // 11
>   }
> 
>   template<typename FunctionType>
>   void submit(FunctionType f)
>   {
>     work_queue.push(std::function<void()>(f));  // 12
>   }
> };
> ```
>
> 实现中有一组工作线程②，并且使用了一个线程安全队列(见第6章)①来管理任务队列。这种情况下，用户不用等待任务，并且任务不需要返回任何值，所以可以使用`std::function<void()>`对任务进行封装。submit()函数会将函数或可调用对象包装成一个`std::function<void()>`实例，并将其推入队列中⑫。
>
> 线程始于构造函数：使用`std::thread::hardware_concurrency()`来获取硬件支持多少个并发线程⑧，这些线程会在worker_thread()成员函数中执行⑨。
>
> **当有异常抛出时，线程启动就会失败，所以需要保证任何已启动的线程都能停止，并且能在这种情况下清理干净。当有异常抛出时，通过使用*try-catch*来设置done标志⑩，还有join_threads类的实例(来自于第8章)③用来汇聚所有线程。当然也需要析构函数：仅设置done标志⑪，并且join_threads确保所有线程在线程池销毁前全部执行完成。注意成员声明的顺序很重要：done标志和worker_queue必须在threads数组之前声明，而数据必须在joiner前声明。这就能确保成员能以正确的顺序销毁；比如，所有线程都停止运行时，队列就可以安全的销毁了。**
>
> worker_thread函数很简单：从任务队列上获取任务⑤，以及同时执行这些任务⑥，执行一个循环直到done标志被设置④。如果任务队列上没有任务，函数会调用`std::this_thread::yield()`让线程休息⑦，并且给予其他线程向任务队列上推送任务的机会。
>
> ```cpp
>   void worker_thread()
>   {
>     while(!done)  // 4
>     {
>       std::function<void()> task;
>       if(work_queue.try_pop(task))  // 5
>       {
>         task();  // 6
>       }
>       else
>       {
>         std::this_thread::yield();  // 7
>       }
>     }
>   }
> ```

一些简单的情况，这样线程池就足以满足要求，特别是任务没有返回值，或需要执行一些阻塞操作的时候。不过，在很多情况下，这样简单的线程池完全不够用，其他情况使用这样简单的线程池可能会出现问题，比如：死锁。同样，在简单例子中，使用`std::async`能提供更好的功能(如第8章中的例子)。

在本章中，我们将了解一下更加复杂的线程池实现，通过添加特性满足用户需求，或减少问题的发生几率。

首先，从已经提交的任务开始说起。

### 等待提交到线程池中的任务

第8章中的例子中，线程间的任务划分完成后，代码会显式生成新线程，主线程通常就是等待新线程在返回调用之前结束，确保所有任务都完成。**使用线程池，就需要等待任务提交到线程池中，而非直接提交给单个线程。**这与基于`std::async`的方法(第8章等待future的例子)类似，使用清单9.1中的简单线程池，使用第4章中提到的工具：条件变量和future。虽然，会增加代码的复杂度，不过，要比直接对任务进行等待的方式好很多。

**通过增加线程池的复杂度，可以直接等待任务完成。使用submit()函数返回一个对任务描述的句柄，用来等待任务的完成。任务句柄会用条件变量或future进行包装，这样能使用线程池来简化代码。**

**一种特殊的情况是，执行任务的线程需要返回一个结果到主线程上进行处理。**你已经在本书中看到多个这样的例子，比如：parallel_accumulate()(第2章)。**这种情况下，需要用future对最终的结果进行转移。**

清单9.2展示了对简单线程池的修改，*<u>通过修改就能等待任务完成，以及在工作线程完成后，返回一个结果到等待线程中去</u>*，**不过`std::packaged_task<>`实例是不可拷贝的，仅是可移动的，所以不能再使用`std::function<>`来实现任务队列，因为`std::function<>`需要存储可复制构造的函数对象。包装一个自定义函数，用来处理只可移动的类型。这就是一个带有函数操作符的类型擦除类。只需要处理那些没有函数和无返回的函数，所以这是一个简单的虚函数调用。**

> 清单9.2 可等待任务的线程池
>
> ```cpp
> class function_wrapper
> {
>   struct impl_base {
>     virtual void call()=0;
>     virtual ~impl_base() {}
>   };
> 
>   std::unique_ptr<impl_base> impl;
>   template<typename F>
>   struct impl_type: impl_base
>   {
>     F f;
>     impl_type(F&& f_): f(std::move(f_)) {}
>     void call() { f(); }
>   };
> public:
>   template<typename F>
>   function_wrapper(F&& f):
>     impl(new impl_type<F>(std::move(f)))
>   {}
> 
>   void operator()() { impl->call(); }
> 
>   function_wrapper() = default;
> 
>   function_wrapper(function_wrapper&& other):
>     impl(std::move(other.impl))
>   {}
> 
>   function_wrapper& operator=(function_wrapper&& other)
>   {
>     impl=std::move(other.impl);
>     return *this;
>   }
> 
>   function_wrapper(const function_wrapper&)=delete;
>   function_wrapper(function_wrapper&)=delete;
>   function_wrapper& operator=(const function_wrapper&)=delete;
> };
> 
> class thread_pool
> {
>   thread_safe_queue<function_wrapper> work_queue;  // 使用function_wrapper，而非使用std::function
> 
>   void worker_thread()
>   {
>     while(!done)
>     {
>       function_wrapper task;
>       if(work_queue.try_pop(task))
>       {
>         task();
>       }
>       else
>       {
>         std::this_thread::yield();
>       }
>     }
>   }
> public:
>   template<typename FunctionType>
>   std::future<typename std::result_of<FunctionType()>::type>  // 1
>     submit(FunctionType f)
>   {
>     typedef typename std::result_of<FunctionType()>::type
>       result_type;  // 2
> 
>     std::packaged_task<result_type()> task(std::move(f));  // 3
>     std::future<result_type> res(task.get_future());  // 4
>     work_queue.push(std::move(task));  // 5
>     return res;  // 6
>   }
>   // 休息一下
> };
> ```
>
> 首先，**修改的是submit()函数①返回一个`std::future<>`保存任务的返回值**，并且允许调用者等待任务完全结束。**因为需要知道提供函数f的返回类型，**所以使用`std::result_of<>`：`std::result_of<FunctionType()>::type`是FunctionType类型的引用实例(如，f)，并且没有参数。同样，函数中可以对result_type typedef②使用`std::result_of<>`。
>
> 然后，将f包装入`std::packaged_task<result_type()>`③，因为f是一个无参数的函数或是可调用对象，能够返回result_type类型的实例。向任务队列推送任务⑤和返回future⑥前，就可以从`std::packaged_task<>`中获取future④。注意，**要将任务推送到任务队列中时，只能使用`std::move()`，因为`std::packaged_task<>`是不可拷贝的。**为了对任务进行处理，队列里面存的就是function_wrapper对象，而非`std::function<void()>`对象。

现在线程池允许等待任务，并且返回任务后的结果。下面的清单就展示了，如何让parallel_accumuate函数使用线程池。

> 清单9.3 parallel_accumulate使用一个可等待任务的线程池
>
> ```cpp
> template<typename Iterator,typename T>
> T parallel_accumulate(Iterator first,Iterator last,T init)
> {
>   unsigned long const length=std::distance(first,last);
> 
>   if(!length)
>     return init;
> 
>   unsigned long const block_size=25;
>   unsigned long const num_blocks=(length+block_size-1)/block_size;  // 1
> 
>   std::vector<std::future<T> > futures(num_blocks-1);
>   thread_pool pool;
> 
>   Iterator block_start=first;
>   for(unsigned long i=0;i<(num_blocks-1);++i)
>   {
>     Iterator block_end=block_start;
>     std::advance(block_end,block_size);
>     futures[i]=pool.submit(accumulate_block<Iterator,T>());  // 2
>     block_start=block_end;
>   }
>   T last_result=accumulate_block<Iterator,T>()(block_start,last);
>   T result=init;
>   for(unsigned long i=0;i<(num_blocks-1);++i)
>   {
>     result+=futures[i].get();
>   }
>   result += last_result;
>   return result;
> }
> ```
>
> 与清单8.4相比，有几个点需要注意一下。首先，**工作量是依据使用的块数(num_blocks①)，而不是线程的数量**。为了利用线程池的最大化可扩展性，需要将工作块划分为最小工作块。当线程池中线程不多时，每个线程将会处理多个工作块，不过随着硬件可用线程数量的增长，会有越来越多的工作块并发执行。
>
> 当你选择“因为能并发执行，最小工作块值的一试”时，就需要谨慎了。**向线程池提交一个任务有一定的开销；让工作线程执行这个任务，并且将返回值保存在`std::future<>`中，对于太小的任务，这样的开销不划算。如果任务块太小，使用线程池的速度可能都不及单线程。**
>
> 假设，任务块的大小合理，就不用为这些事而担心：打包任务、获取future或存储之后要汇入的`std::thread`对象；使用线程池的时候，这些都需要注意。之后，就是调用submit()来提交任务②。

线程池也需要注意异常安全。任何异常都会通过submit()返回给future，并在获取future的结果时，抛出异常。如果函数因为异常退出，线程池的析构函数会丢掉那些没有完成的任务，等待线程池中的工作线程完成工作。

在简单的例子中，这个线程池工作的还算不错，因为这里的任务都是相互独立的。不过，当任务队列中的任务有依赖关系时，这个线程池就不能胜任了。

### 等待依赖任务

如果只用简单的线程池进行替换，例如：第4章替换`std::async`的线程池。只有固定数量的线程，因为线程池中没有空闲的线程，线程会等待没有被安排的任务。因此，需要和第8章中类似的解决方案：当等待某个数据块完成时，去处理未完成的数据块。**如果使用线程池来管理任务列表和相关线程——使用线程池的主要原因——就不用再去访问任务列表了。可以对线程池做一些改动，自动完成这些事情。**

最简单的方法就是在thread_pool中添加一个新函数，来执行任务队列上的任务，并对线程池进行管理。高级线程池的实现可能会在等待函数中添加逻辑，或等待其他函数来处理这个任务，优先的任务会让其他的任务进行等待。下面清单中的实现，就展示了一个新run_pending_task()函数，对于快速排序的修改将会在清单9.5中展示。

> 清单9.4 run_pending_task()函数实现
>
> ```cpp
> void thread_pool::run_pending_task()
> {
>   function_wrapper task;
>   if(work_queue.try_pop(task))
>   {
>     task();
>   }
>   else
>   {
>     std::this_thread::yield();
>   }
> }
> ```
>
> run_pending_task()的实现去掉了在worker_thread()函数的主循环。函数任务队列中有任务的时候，执行任务；要是没有的话，就会让操作系统对线程进行重新分配。

下面快速排序算法的实现要比清单8.1中版本简单许多，因为所有线程管理逻辑都被移入到线程池。

> 清单9.5 基于线程池的快速排序实现
>
> ```cpp
> template<typename T>
> struct sorter  // 1
> {
>   thread_pool pool;  // 2
> 
>   std::list<T> do_sort(std::list<T>& chunk_data)
>   {
>     if(chunk_data.empty())
>     {
>       return chunk_data;
>     }
> 
>     std::list<T> result;
>     result.splice(result.begin(),chunk_data,chunk_data.begin());
>     T const& partition_val=*result.begin();
> 
>     typename std::list<T>::iterator divide_point=
>       std::partition(chunk_data.begin(),chunk_data.end(),
>                      [&](T const& val){return val<partition_val;});
> 
>     std::list<T> new_lower_chunk;
>     new_lower_chunk.splice(new_lower_chunk.end(),
>                            chunk_data,chunk_data.begin(),
>                            divide_point);
> 
>     std::future<std::list<T> > new_lower=  // 3
>       pool.submit(std::bind(&sorter::do_sort,this,
>                             std::move(new_lower_chunk)));
> 
>     std::list<T> new_higher(do_sort(chunk_data));
> 
>     result.splice(result.end(),new_higher);
>     while(!new_lower.wait_for(std::chrono::seconds(0)) ==
>       std::future_status::timeout)
>     {
>       pool.run_pending_task();  // 4
>     }
> 
>     result.splice(result.begin(),new_lower.get());
>     return result;
>   }
> };
> 
> template<typename T>
> std::list<T> parallel_quick_sort(std::list<T> input)
> {
>   if(input.empty())
>   {
>     return input;
>   }
>   sorter<T> s;
> 
>   return s.do_sort(input);
> }
> ```
>
> 与清单8.1相比，这里将实际工作放在sorter类模板的do_sort()成员函数中执行①，即使例子中仅对thread_pool实例进行包装②。
>
> 线程和任务管理，在线程等待的时候，就会少向线程池中提交一个任务③，并且执行任务队列上未完成的任务④。需要显式的管理线程和栈上要排序的数据块。当有任务提交到线程池中，可以使用`std::bind()`绑定this指针到do_sort()上，绑定是为了让数据块进行排序。这种情况下，需要对new_lower_chunk使用`std::move()`将其传入函数，数据移动要比拷贝的方式开销少。

虽然，使用等待其他任务的方式，解决了死锁问题，这个线程池距离理想的线程池很远。

首先，每次对submit()的调用和对run_pending_task()的调用，访问的都是同一个队列。在第8章中，当多线程去修改一组数据，就会对性能有所影响，所以需要解决这个问题。

### 避免队列中的任务竞争

线程每次调用线程池的submit()函数，都会推送一个任务到工作队列中。就像工作线程为了执行任务，从任务队列中获取任务一样。这意味着随着处理器的增加，在任务队列上就会有很多的竞争，这会让性能下降。**使用无锁队列会让任务没有明显的等待，但是乒乓缓存会消耗大量的时间。**

**为了避免乒乓缓存，每个线程建立独立的任务队列。**这样，每个线程就会将新任务放在自己的任务队列上，并且当线程上的任务队列没有任务时，去全局的任务列表中取任务。下面列表中的实现，使用了一个thread_local变量，来保证每个线程都拥有自己的任务列表(如全局列表那样)。

> 清单9.6 线程池——线程具有本地任务队列
>
> ```cpp
> class thread_pool
> {
>   thread_safe_queue<function_wrapper> pool_work_queue;
> 
>   typedef std::queue<function_wrapper> local_queue_type;  // 1
>   static thread_local std::unique_ptr<local_queue_type>
>     local_work_queue;  // 2
> 
>   void worker_thread()
>   {
>     local_work_queue.reset(new local_queue_type);  // 3
>     while(!done)
>     {
>       run_pending_task();
>     }
>   }
> 
> public:
>   template<typename FunctionType>
>   std::future<typename std::result_of<FunctionType()>::type>
>     submit(FunctionType f)
>   {
>     typedef typename std::result_of<FunctionType()>::type result_type;
> 
>     std::packaged_task<result_type()> task(f);
>     std::future<result_type> res(task.get_future());
>     if(local_work_queue)  // 4
>     {
>       local_work_queue->push(std::move(task));
>     }
>     else
>     {
>       pool_work_queue.push(std::move(task));  // 5
>     }
>     return res;
>   }
> 
>   void run_pending_task()
>   {
>     function_wrapper task;
>     if(local_work_queue && !local_work_queue->empty())  // 6
>     {
>       task=std::move(local_work_queue->front());
>       local_work_queue->pop();
>       task();
>     }
>     else if(pool_work_queue.try_pop(task))  // 7
>     {
>       task();
>     }
>     else
>     {
>       std::this_thread::yield();
>     }
>   }
> // rest as before
> };
> ```
>
> 因为不希望非线程池中的线程也拥有一个任务队列，使用`std::unique_ptr<>`指向线程本地的工作队列②；这个指针在worker_thread()中进行初始化③。`std:unique_ptr<>`的析构函数会保证在线程退出的时候，工作队列被销毁。
>
> submit()会检查当前线程是否具有一个工作队列④。如果有，就是线程池中的线程，可以将任务放入线程的本地队列中；否者，就像之前一样将这个任务放在线程池中的全局队列中⑤。
>
> run_pending_task()⑥中的检查和之前类似，只是要对是否存在本地任务队列进行检查。如果存在，就会从队列中的第一个任务开始处理；注意本地任务队列可以是一个普通的`std::queue<>`①，因为这个队列只能被一个线程所访问，就不存在竞争。如果本地线程上没有任务，就会从全局工作列表上获取任务⑦。

这样就能有效避免竞争，不过当任务分配不均时，造成的结果就是：某个线程本地队列中有很多任务的同时，其他线程无所事事。例如：举一个快速排序的例子，只有一开始的数据块能在线程池上被处理，因为剩余部分会放在工作线程的本地队列上进行处理，这样的使用方式也违背使用线程池的初衷。

幸好，这个问题是有解：本地工作队列和全局工作队列上没有任务时，可从别的线程队列中窃取任务。

### 窃取任务

为了让没有任务的线程能从其他线程的任务队列中获取任务，就需要本地任务列表可以进行访问，这样才能让run_pending_tasks()窃取任务。需要每个线程在线程池队列上进行注册，或由线程池指定一个线程。同样，还需要保证数据队列中的任务适当的被同步和保护，这样队列的不变量就不会被破坏。

实现一个无锁队列，让其拥有线程在其他线程窃取任务的时候，能够推送和弹出一个任务是可能的；不过，这个队列的实现就超出了本书的讨论范围。为了证明这种方法的可行性，将使用一个互斥量来保护队列中的数据。我们希望任务窃取是一个不常见的现象，这样就会减少对互斥量的竞争，并且使得简单队列的开销最小。下面，实现了一个简单的基于锁的任务窃取队列。

……

## 中断线程

很多情况下，使用信号来终止一个长时间运行的线程是合理的。这种线程的存在，可能是因为工作线程所在的线程池被销毁，或是用户显式的取消了这个任务，亦或其他各种原因。不管是什么原因，原理都一样：需要使用信号来让未结束线程停止运行。**这里需要一种合适的方式让线程主动的停下来，而非让线程戛然而止。**

在了解一下应该如何实现这种机制前，先来了解一下启动和中断线程的接口。

### 启动和中断线程

先看一下外部接口，需要从可中断线程上获取些什么？最起码需要和`std::thread`相同的接口，还要多加一个interrupt()函数：

```cpp
class interruptible_thread
{
public:
  template<typename FunctionType>
  interruptible_thread(FunctionType f);
  void join();
  void detach();
  bool joinable() const;
  void interrupt();
};
```

类内部可以使用`std::thread`来管理线程，并且使用一些自定义数据结构来处理中断。现在，从线程的角度能看到什么呢？“能用这个类来中断线程”——需要一个断点(*interruption point*)。**在不添加多余的数据的前提下，为了使断点能够正常使用，就需要使用一个没有参数的函数：interruption_point()。**这意味着中断数据结构可以访问thread_local变量，并在线程运行时，对变量进行设置，因此当线程调用interruption_point()函数时，就会去检查当前运行线程的数据结构。我们将在后面看到interruption_point()的具体实现。

thread_local标志是不能使用普通的`std::thread`管理线程的主要原因；需要使用一种方法分配出一个可访问的interruptible_thread实例，就像新启动一个线程一样。在使用已提供函数来做这件事情前，需要将interruptible_thread实例传递给`std::thread`的构造函数，创建一个能够执行的线程，就像下面的代码清单所实现。

> 清单9.9 interruptible_thread的基本实现
>
> ```cpp
> class interrupt_flag
> {
> public:
> void set();
> bool is_set() const;
> };
> thread_local interrupt_flag this_thread_interrupt_flag;  // 1
> 
> class interruptible_thread
> {
> std::thread internal_thread;
> interrupt_flag* flag;
> public:
> template<typename FunctionType>
> interruptible_thread(FunctionType f)
> {
>  std::promise<interrupt_flag*> p;  // 2
>  internal_thread=std::thread([f,&p]{  // 3
>    p.set_value(&this_thread_interrupt_flag);
>    f();  // 4
>  });
>  flag=p.get_future().get();  // 5
> }
> void interrupt()
> {
>  if(flag)
>  {
>    flag->set();  // 6
>  }
> }
> };
> ```
>
> 提供函数f是包装了一个lambda函数③，线程将会持有f副本和本地promise变量(p)的引用②。在新线程中，lambda函数设置promise变量的值到this_thread_interrupt_flag(在thread_local①中声明)的地址中，为的是让线程能够调用提供函数的副本④。调用线程会等待与其future相关的promise就绪，并且将结果存入到flag成员变量中⑤。注意，即使lambda函数在新线程上执行，对本地变量p进行悬空引用，都没有问题，因为在新线程返回之前，interruptible_thread构造函数会等待变量p，直到变量p不被引用。实现没有考虑处理汇入线程，或分离线程。所以，需要flag变量在线程退出或分离前已经声明，这样就能避免悬空问题。
>
> interrupt()函数相对简单：需要一个线程去做中断时，需要一个合法指针作为一个中断标志，所以可以仅对标志进行设置⑥。















































