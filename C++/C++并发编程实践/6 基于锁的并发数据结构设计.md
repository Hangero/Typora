# 基于锁的并发数据结构设计

**本章主要内容**

- 并发数据结构设计的意义
- 指导如何设计
- 实现为并发设计的数据结构

## 为并发设计的意义何在

设计并发数据结构，意味着多个线程可以并发的访问这个数据结构，线程可对这个数据结构做相同或不同的操作，并且每一个线程都能在自己的自治域中看到该数据结构。且在多线程环境下，无数据丢失和损毁，所有的数据需要维持原样，且无条件竞争。这样的数据结构，称之为“线程安全”的数据结构。

要为线程提供并发访问数据结构的机会。**本质上，是使用互斥量提供互斥特性：在互斥量的保护下，同一时间内只有一个线程可以获取互斥锁。**互斥量为了保护数据，显式的阻止了线程对数据结构的并发访问。

**这被称为*序列化*(*serialzation*)：线程轮流访问被保护的数据。这其实是对数据进行串行的访问，而非并发。**因此，你需要对数据结构的设计进行仔细斟酌，确保其能真正并发访问。虽然，一些数据结构有着比其他数据结构多的并发访问范围，但是在所有情况下的思路都是一样的：**减少保护区域，减少序列化操作**，就能提升并发访问的潜力。

### 数据结构并发设计的指导与建议

当设计并发数据结构时，有两方面需要考量：一是确保访问是安全的，二是能真正的并发访问。在第3章的时候，已经对如何保证数据结构是线程安全的做过简单的描述：

- 确保无线程能够看到，数据结构的“不变量”破坏时的状态。
- 小心那些会引起条件竞争的接口，提供完整操作的函数，而非操作步骤。
- 注意数据结构的行为是否会产生异常，从而确保“不变量”的状态稳定。
- 将死锁的概率降到最低。使用数据结构时，需要限制锁的范围，且避免嵌套锁的存在。

在你思考设计细节前，你还需要考虑这个数据结构对于使用者来说有什么限制；**当一个线程通过一个特殊的函数对数据结构进行访问时，那么还有哪些函数能被其他的线程安全调用呢？**

这是一个很重要的问题，普通的构造函数和析构函数需要独立访问数据结构，所以用户在使用的时候，就不能在构造函数完成前，或析构函数完成后对数据结构进行访问

第二个方面是，确保真正的并发访问。这里没法提供更多的指导意见；不过，作为一个数据结构的设计者，在设计数据结构时，自行考虑以下问题：

- 锁的范围中的操作，是否允许在所外执行？
- **数据结构中不同的区域是否能被不同的互斥量所保护**？
- 所有操作都需要同级互斥量保护吗？
- 能否对数据结构进行简单的修改，以增加并发访问的概率，且不影响操作语义？

**这些问题都源于一个指导思想：如何让序列化访问最小化，让真实并发最大化？**允许线程并发读取的数据结构并不少见，而对数据结构的修改，必须是单线程独立访问。这种结构，类似于`boost::shared_mutex`。同样的，这种数据结构也很常见——支持在多线程执行不同的操作时，并序列化执行相同的操作的线程(你很快就能看到)。

## 基于锁的并发数据结构

### 线程安全栈——使用锁

我们先把第3章中线程安全的栈拿过来看看：(这里试图实现一个线程安全版的`std:stack<>`)

清单6.1 线程安全栈的类定义

```cpp
#include <exception>

struct empty_stack: std::exception
{
  const char* what() const throw();
};

template<typename T>
class threadsafe_stack
{
private:
  std::stack<T> data;
  mutable std::mutex m;
public:
  threadsafe_stack(){}
  threadsafe_stack(const threadsafe_stack& other)
  {
    std::lock_guard<std::mutex> lock(other.m);
    data=other.data;
  }

  threadsafe_stack& operator=(const threadsafe_stack&) = delete;

  void push(T new_value)
  {
    std::lock_guard<std::mutex> lock(m);
    data.push(std::move(new_value));  // 1
  }
  std::shared_ptr<T> pop()
  {
    std::lock_guard<std::mutex> lock(m);
    if(data.empty()) throw empty_stack();  // 2
    std::shared_ptr<T> const res(
      std::make_shared<T>(std::move(data.top())));  // 3
    data.pop();  // 4
    return res;
  }
  void pop(T& value)
  {
    std::lock_guard<std::mutex> lock(m);
    if(data.empty()) throw empty_stack();
    value=std::move(data.top());  // 5
    data.pop();  // 6
  }
  bool empty() const
  {
    std::lock_guard<std::mutex> lock(m);
    return data.empty();
  }
};
```

首先，互斥量m能保证基本的线程安全，那就是对每个成员函数进行加锁保护。这就保证在同一时间内，只有一个线程可以访问到数据，所以能够保证，数据结构的“不变量”被破坏时，不会被其他线程看到。

其次，在empty()和pop()成员函数之间会存在潜在的竞争，不过代码会在pop()函数上锁时，显式的查询栈是否为空，所以这里的竞争是非恶性的。**pop()通过对弹出值的直接返回，就可避免`std::stack<>`中top()和pop()两成员函数之间的潜在竞争。**

> 这里的分析感觉很受启发，建议看书。重视每一处**构造对象**、**抛出异常**和**数据修改**，思考是否安全，然后思考是否会**死锁**

序列化线程会隐性的限制程序性能，这就是栈争议声最大的地方。……

### 线程安全队列——使用锁和条件变量

> 清单6.2 使用条件变量实现的线程安全队列
>
> ```cpp
> template<typename T>
> class threadsafe_queue
> {
> private:
>   mutable std::mutex mut;
>   std::queue<T> data_queue;
>   std::condition_variable data_cond;
> 
> public:
>   threadsafe_queue()
>   {}
> 
>   void push(T new_value)
>   {
>     std::lock_guard<std::mutex> lk(mut);
>     data_queue.push(std::move(data));
>     data_cond.notify_one();  // 1
>   }
> 
>   void wait_and_pop(T& value)  // 2
>   {
>     std::unique_lock<std::mutex> lk(mut);
>     data_cond.wait(lk,[this]{return !data_queue.empty();});
>     value=std::move(data_queue.front());
>     data_queue.pop();
>   }
> 
>   std::shared_ptr<T> wait_and_pop()  // 3
>   {
>     std::unique_lock<std::mutex> lk(mut);
>     data_cond.wait(lk,[this]{return !data_queue.empty();});  // 4
>     std::shared_ptr<T> res(
>       std::make_shared<T>(std::move(data_queue.front())));
>     data_queue.pop();
>     return res;
>   }
> 
>   bool try_pop(T& value)
>   {
>     std::lock_guard<std::mutex> lk(mut);
>     if(data_queue.empty())
>       return false;
>     value=std::move(data_queue.front());
>     data_queue.pop();
>     return true;
>   }
> 
>   std::shared_ptr<T> try_pop()
>   {
>     std::lock_guard<std::mutex> lk(mut);
>     if(data_queue.empty())
>       return std::shared_ptr<T>();  // 5
>     std::shared_ptr<T> res(
>       std::make_shared<T>(std::move(data_queue.front())));
>     data_queue.pop();
>     return res;
>   }
> 
>   bool empty() const
>   {
>     std::lock_guard<std::mutex> lk(mut);
>     return data_queue.empty();
>   }
> };
> ```

除了在push()①中调用data_cond.notify_one()，以及wait_and_pop()②③，6.2中对队列的实现与6.1中对栈的实现十分相近。两个重载try_pop()除了在队列为空时抛出异常，其他的与6.1中pop()函数完全一样。不同的是，在6.1中对值的检索会返回一个bool值，而在6.2中，当指针指向空值的时候会返回NULL指针⑤，这同样也是实现栈的一个有效途径。所以，即使排除掉wait_and_pop()函数，之前对栈的分析依旧适用于这里。

wiat_and_pop()函数是等待队列向栈进行输入的一个解决方案；比**起持续调用empty()，等待线程调用wait_and_pop()函数和数据结构处理等待中的条件变量（`std::condition_variable data_cond`）的方式要好很多。**对于data_cond.wait()的调用，直到队列中有一个元素的时候，才会返回，所以你就不用担心会出现一个空队列的情况了，还有，数据会一直被互斥锁保护。因为不变量这里并未发生变化，所以函数不会添加新的条件竞争或是死锁的可能。

**异常安全在这里的会有一些变化，当不止一个线程等待对队列进行推送操作是，只会有一个线程，因得到data_cond.notify_one()，而继续工作着。但是，如果这个工作线程在wait_and_pop()中抛出一个异常，例如：构造新的`std::shared_ptr<>`对象④时抛出异常，那么其他线程则会永世长眠。**

> 注意这个分析！

当这种情况是不可接受时，这里的调用就需要改成data_cond.notify_all()，这个函数将唤醒所有的工作线程，不过，当大多线程发现队列依旧是空时，又会耗费很多资源让线程重新进入睡眠状态。

第二种替代方案是，**当有异常抛出的时候，让wait_and_pop()函数调用notify_one()**，从而让个另一个线程可以去尝试索引存储的值。

第三种替代方案就是，**将`std::shared_ptr<>`的初始化过程移到push()中，并且存储`std::shared_ptr<>`实例，而非直接使用数据的值。**将`std::shared_ptr<>`拷贝到内部`std::queue<>`中，就不会抛出异常了，这样wait_and_pop()又是安全的了。下面的程序清单，就是根据第三种方案进行修改的。

> 清单6.3 持有`std::shared_ptr<>`实例的线程安全队列
>
> ```cpp
> template<typename T>
> class threadsafe_queue
> {
> private:
>   mutable std::mutex mut;
>   std::queue<std::shared_ptr<T> > data_queue;
>   std::condition_variable data_cond;
> public:
>   threadsafe_queue()
>   {}
> 
>   void wait_and_pop(T& value)
>   {
>     std::unique_lock<std::mutex> lk(mut);
>     data_cond.wait(lk,[this]{return !data_queue.empty();});
>     value=std::move(*data_queue.front());  // 1
>     data_queue.pop();
>   }
> 
>   bool try_pop(T& value)
>   {
>     std::lock_guard<std::mutex> lk(mut);
>     if(data_queue.empty())
>       return false;
>     value=std::move(*data_queue.front());  // 2
>     data_queue.pop();
>     return true;
>   }
> 
>   std::shared_ptr<T> wait_and_pop()
>   {
>     std::unique_lock<std::mutex> lk(mut);
>     data_cond.wait(lk,[this]{return !data_queue.empty();});
>     std::shared_ptr<T> res=data_queue.front();  // 3
>     data_queue.pop();
>     return res;
>   }
> 
>   std::shared_ptr<T> try_pop()
>   {
>     std::lock_guard<std::mutex> lk(mut);
>     if(data_queue.empty())
>       return std::shared_ptr<T>();
>     std::shared_ptr<T> res=data_queue.front();  // 4
>     data_queue.pop();
>     return res;
>   }
> 
>   void push(T new_value)
>   {
>     std::shared_ptr<T> data(std::make_shared<T>(std::move(new_value)));  // 5
>     std::lock_guard<std::mutex> lk(mut);
>     data_queue.push(data);
>     data_cond.notify_one();
>   }
> 
>   bool empty() const
>   {
>     std::lock_guard<std::mutex> lk(mut);
>     return data_queue.empty();
>   }
> };
> ```

为让`std::shared_ptr<>`持有数据的结果显而易见：弹出函数会持有一个变量的引用，为了接收这个新值，必须对存储的指针进行解引用①，②；并且，在返回到调用函数前，弹出函数都会返回一个`std::shared_ptr<>`实例，这里实例可以在队列中做检索③，④。

**`std::shared_ptr<>`持有数据的好处：新的实例分配结束时，不会被锁在push()⑤当中(而在清单6.2中，只能在pop()持有锁时完成)。**因为内存分配操作的需要在性能上付出很高的代价(性能较低)，所以**使用`std::shared_ptr<>`的方式对队列的性能有很大的提升，其减少了互斥量持有的时间**，允许其他线程在分配内存的同时，对队列进行其他的操作。

如同栈的例子，使用互斥量保护整个数据结构，不过会限制队列对并发的支持；虽然，多线程可能被队列中的各种成员函数所阻塞，但是仍有一个线程能在任意时间内进行工作。不过，这种限制的部分来源是因为在实现中使用了`std::queue<>`；因为使用标准容器的原因，数据处于保护中。要对数据结构实现进行具体的控制，需要提供更多细粒度锁，来完成更高级的并发。

### 线程安全队列——使用细颗粒锁和条件变量















































