# C++内存模型和原子类型操作

**本章主要内容**

- C++11内存模型详解
- 标准库提供的原子类型
- 使用各种原子类型
- 原子操作实现线程同步功能

## 内存模型基础

### 对象和内存位置

在一个C++程序中的所有数据都是由对象(objects)构成。“对象”仅仅是对C++数据构建块的一个声明。C++标准定义类对象为“存储区域”，但对象还是可以将自己的特性赋予其他对象，比如，其类型和生命周期。

这里有四个需要牢记的原则：

1. 每一个变量都是一个对象，包括作为其成员变量的对象。
2. 每个对象至少占有一个内存位置。
3. 基本类型都有确定的内存位置(无论类型大小如何，即使他们是相邻的，或是数组的一部分)。
4. 相邻位域是相同内存中的一部分。

### 对象、内存位置和并发

这部分对于C++的多线程应用来说是至关重要的：所有东西都在内存中。当两个线程访问不同(*separate*)的内存位置时，不会存在任何问题，一切都工作顺利。而另一种情况下，当两个线程访问同一(*same*)个内存位置，你就要小心了。如果没有线程更新内存位置上的数据，那还好；只读数据不需要保护或同步。当有线程对内存位置上的数据进行修改，那就有可能会产生条件竞争。

**为了避免条件竞争，两个线程就需要一定的执行顺序**。

**第一种方式，使用互斥量来确定访问的顺序**；当同一互斥量在两个线程同时访问前被锁住，那么在同一时间内就只有一个线程能够访问到对应的内存位置，所以后一个访问必须在前一个访问之后。**另一种方式是使用原子操作(*atmic operations*)同步机制，决定两个线程的访问顺序。**使用原子操作来规定顺序在5.3节中会有介绍。当多于两个线程访问同一个内存地址时，对每个访问这都需要定义一个顺序。

**如果不去规定两个不同线程对同一内存地址访问的顺序，那么访问就不是原子的**；并且，当两个线程都是“作者”时，就会产生数据竞争和未定义行为。

> 当程序中的对同一内存地址中的数据访问存在竞争，你可以使用原子操作来避免未定义行为。当然，这不会影响竞争的产生——**原子操作并没有指定访问顺序——但原子操作把程序拉回了定义行为的区域内。**

### 修改顺序

每一个在C++程序中的对象，都有(由程序中的所有线程对象)确定好的修改顺序(*modification order*)，在的初始化开始阶段确定。在大多数情况下，这个顺序不同于执行中的顺序，但是在给定的执行程序中，所有线程都需要遵守这顺序。如果对象不是一个原子类型(将在5.2节详述)，你必要确保有足够的同步操作，来确定每个线程都遵守了变量的修改顺序。当不同线程在不同序列中访问同一个值时，你可能就会遇到数据竞争或未定义行为(详见5.1.2节)。如果你使用原子操作，编译器就有责任去替你做必要的同步。

这一要求意味着：投机执行是不允许的，因为当线程按修改顺序访问一个特殊的输入，之后的读操作，必须由线程返回较新的值，并且之后的写操作必须发生在修改顺序之后。同样的，在同一线程上允许读取对象的操作，要不返回一个已写入的值，要不在对象的修改顺序后(也就是在读取后)再写入另一个值。虽然，所有线程都需要遵守程序中每个独立对象的修改顺序，但它们没有必要遵守在独立对象上的相对操作顺序。在5.3.3节中会有更多关于不同线程间操作顺序的内容。

## C++中的原子操作和原子类型

原子操作是一类不可分割的操作，当这样操作在任意线程中进行一半的时候，你是不能查看的；它的状态要不就是完成，要不就是未完成。

> 因此可以避免在操作过程中出现数据竞争

### 标准原子类型

标准原子类型都很相似：它们(大多数)都有一个is_lock_free()成员函数，这个函数允许用户决定是否直接对一个给定类型使用原子指令(x.is_lock_free()返回true)，或对编译器和运行库使用内部锁(x.is_lock_free()返回false)。

对于标准类型进行`typedef T`，相关的原子类型就在原来的类型名前加上`atomic_`的前缀：`atomic_T`。除了singed类型的缩写是s，unsigned的缩写是u，和long long的缩写是llong之外，这种方式也同样适用于内置类型。对于`std::atomic<T>`模板，使用对应的T类型去特化模板的方式，要好于使用别名的方式。

通常，标准原子类型是不能拷贝和赋值，他们没有拷贝构造函数和拷贝赋值操作。但是，因为可以隐式转化成对应的内置类型，所以这些类型依旧支持赋值，可以使用

- load()
- store()
- exchange()
- compare_exchange_weak()
- compare_exchange_strong()

它们都支持复合赋值符：+=, -=, *=, |= 等等。并且使用整型和指针的特化类型还支持 ++ 和 --。当然，这些操作也有功能相同的成员函数所对应：fetch_add(), fetch_or() 等等。返回值通过赋值操作返回，并且成员函数不是对值进行存储(在有赋值符操作的情况下)，就是对值进行操作(在命名函数中)。这就能避免赋值操作符返回引用。为了获取存储在引用的的值，代码需要执行单独的读操作，从而允许另一个线程在赋值和读取进行的同时修改这个值，这也就为条件竞争打开了大门。

`std::atomic<>`类模板不仅仅一套特化的类型，其作为一个原发模板也可以使用用户定义类型创建对应的原子变量。因为，它是一个通用类模板，很多成员函数的操作在这种情况下有所限制

每种函数类型的操作都有一个可选内存排序参数，这个参数可以用来指定所需存储的顺序

1. `Store`操作：memory_order_relaxed, memory_order_release, memory_order_seq_cst。
2. `Load`操作：memory_order_relaxed, memory_order_consume, memory_order_acquire, memory_order_seq_cst。
3. `Read-modify-write`(读-改-写)操作：memory_order_relaxed, memory_order_consume, memory_order_acquire, memory_order_release, memory_order_acq_rel, memory_order_seq_cst。
   所有操作的默认顺序都是memory_order_seq_cst。

### `std::atomic`的相关操作

最基本的原子整型类型就是`std::atomic<bool>`。

虽然它依旧不能拷贝构造和拷贝赋值，但是你可以使用一个非原子的bool类型构造它，所以它可以被初始化为true或false，并且你也可以从一个非原子bool变量赋值给`std::atomic<bool>`的实例：

```cpp
std::atomic<bool> b(true);
b=false;
```

虽然有内存顺序语义指定，但是**使用store()去写入**(true或false)还是好于`std::atomic_flag`中限制性很强的clear()。同样的，test_and_set()函数也可以被**更加通用的exchange()**成员函数所替换，exchange()成员函数允许你使用你新选的值替换已存储的值，并且自动的检索原始值。`std::atomic<bool>`也支持对值的普通(不可修改)查找，其会将对象隐式的转换为一个普通的bool值，或显式地调用load()来完成。如你预期，**store()是一个存储操作，而load()是一个加载操作。exchange()是一个“读-改-写”操作**：

```cpp
std::atomic<bool> b;
bool x=b.load(std::memory_order_acquire);
b.store(true);
x=b.exchange(false, std::memory_order_acq_rel);
```

#### 存储一个新值(或旧值)取决于当前值

这是一种新型操作，叫做“**比较/交换**”，它的形式表现为**`compare_exchange_weak()`和`compare_exchange_strong()`**成员函数。“比较/交换”操作是原子类型编程的基石，它比较原子变量的当前值和提供的预期值：

- 当两值相等时，存储预期值。
- 当两值不等，预期值就会被更新为原子变量中的值。

“比较/交换”函数值是一个bool变量，当返回true时执行存储操作，当false则更新期望值。

> [**CAS**](https://blog.csdn.net/weixin_43847283/article/details/125469985?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167887779716800186564814%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=167887779716800186564814&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-125469985-null-null.142^v73^control,201^v4^add_ask,239^v2^insert_chatgpt&utm_term=%E6%AF%94%E8%BE%83%2F%E4%BA%A4%E6%8D%A2&spm=1018.2226.3001.4187)
>
> 它包含三个操作数——内存位置、预期原值及更新值。
> 执行CAS操作的时候，将内存位置的值与预期原值比较：
>
> - 如果相匹配，那么处理器会自动将该位置值更新为新值
> - 如果不匹配，处理器不做任何操作，多个线程同时执行CAS操作只有一个会成功。
>
> CAS有3个操作数，位置内存值V，旧的预期值A，要修改的更新值B。
> 当且仅当旧的预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做或重来
> 当它重来重试的这种行为成为----自旋！！！
>
> <img src="https://img-blog.csdnimg.cn/3b0fe9a87b2b41dfb39a9f7e180edd86.png" alt="img" style="zoom: 33%;" />
>
> ```c
> //CAS用C语言描述的代码
> int compare_and_swap (int* reg, int oldval, int newval) 
> {
>   ATOMIC();
>   int old_reg_val = *reg;
>   if (old_reg_val == oldval) 
>      *reg = newval;
>   END_ATOMIC();
>   return old_reg_val;
> }
> ```
>
> 

##### compare_exchange_weak()

对于compare_exchange_weak()函数，当原始值与预期值一致时，存储也可能会不成功；在这个例子中变量的值不会发生改变，并且compare_exchange_weak()的返回是false。

> 可能原因是，线程多于处理器数量，未完成修改时就被系统替换，原因时时间，而不是变量值。

因为compare_exchange_weak()可以“伪失败”，所以这里通常使用一个循环：

```cpp
bool expected=false;
extern atomic<bool> b; // 设置些什么
while(!b.compare_exchange_weak(expected,true) && !expected);
```

##### compare_exchange_strong()

如果实际值与期望值不符，compare_exchange_strong()就能保证值返回false。这就能消除对循环的需要，就可以知道是否成功的改变了一个变量，或已让另一个线程完成。

如果你想要改变变量值，且无论初始值是什么(可能是根据当前值更新了的值)，更新后的期望值将会变更有用；经历每次循环的时候，期望值都会重新加载，所以当没有其他线程同时修改期望时，循环中对compare_exchange_weak()或compare_exchange_strong()的调用都会在下一次(第二次)成功。

- 如果**值的计算很容易存储**，那么使用`compare_exchange_weak()`能更好的避免一个双重循环的执行，即使`compare_exchange_weak()`可能会“伪失败”(因此`compare_exchange_strong()`包含一个循环)。
- 如果**值计算的存储本身是耗时**，那么当期望值不变时，使用`compare_exchange_strong()`可以避免对值的重复计算。对于`std::atomic<bool>`这些都不重要——毕竟只可能有两种值——但是对于其他的原子类型就有较大的影响了。

第二简单的原子类型就是特化原子指针——`std::atomic<T*>`，接下来就看看它是如何工作的吧

### std::atomic:指针运算

原子指针类型，可以使用内置类型或自定义类型T，通过特化`std::atomic<T*>`进行定义。虽然接口几乎一致，但是它的操作是对于相关的类型的指针。

`std::atomic<T*>`也有load(), store(), exchange(), compare_exchange_weak()和compare_exchage_strong()成员函数，与`std::atomic<bool>`的语义相同，**返回值是一个普通的`T*`值，而非是`std::atomic<T*>`对象的引用**，所以调用代码可以基于之前的值进行操作：

`std::atomic<T*>`为指针运算提供新的操作。基本操作有：

- 存储地址可以做原子加法和减法，为`+=, -=, ++, --`提供简易的封装。

  > 如果x是`std::atomic<Foo*>`类型的数组的首地址，然后x+=3让其偏移到第四个元素的地址，并且返回一个普通的`Foo*`类型值，这个指针值是指向数组中第四个元素。

- fetch_add()和fetch_sub()

```cpp
class Foo{};
Foo some_array[5];
std::atomic<Foo*> p(some_array);
Foo* x=p.fetch_add(2);  // p加2，并返回原始值
assert(x==some_array);
assert(p.load()==&some_array[2]);
x=(p-=1);  // p减1，并返回原始值
assert(x==&some_array[1]);
assert(p.load()==&some_array[1]);

//函数也允许内存顺序语义作为给定函数的参数：
p.fetch_add(3,std::memory_order_release);
```

### std::atomic<>主要类的模板

不是任何自定义类型都可以使用`std::atomic<>`的：需要满足一定的- 标准才行。为了使用`std::atomic<UDT>`(UDT是用户定义类型)：

- 必须有拷贝赋值运算符，不能有任何虚函数或虚基类，以及必须使用编译器创建的拷贝赋值操作
- 自定义类型中所有的基类和非静态数据成员也都需要支持拷贝赋值操作
- 必须是“位可比的”(*bitwise equality comparable*)

<img src="/home/suyu/.config/Typora/typora-user-images/image-20230315192956530.png" alt="image-20230315192956530" style="zoom: 50%;" />

### 原子操作的释放函数

……

C++标准库也对在一个原子类型中的`std::shared_ptr<>`智能指针类型提供释放函数。这打破了“只有原子类型，才能提供原子操作”的原则，这里`std::shared_ptr<>`肯定不是原子类型。但是，C++标准委员会感觉对此提供额外的函数是很重要的。可使用的原子操作有：load, store, exchange和compare/exchange，这些操作重载了标准原子类型的操作，并且获取一个`std::shared_ptr<>*`作为第一个参数：

```cpp
std::shared_ptr<my_data> p;
void process_global_data()
{
  std::shared_ptr<my_data> local=std::atomic_load(&p);
  process_data(local);
}
void update_global_data()
{
  std::shared_ptr<my_data> local(new my_data);
  std::atomic_store(&p,local);
}

```



## 同步操作和强制排序

标准原子类型不仅仅是为了避免数据竞争所造成的未定义操作，它们还**允许用户对不同线程上的操作进行强制排序。这种强制排序是数据保护和同步操作的基础**，例如，`std::mutex`和`std::future<>`。所以，让我继续了解本章的真实意义：内存模型在并发方面的细节，如何使用原子操作同步数据和强制排序。

假设你有两个线程，一个向数据结构中填充数据，另一个读取数据结构中的数据。为了避免恶性条件竞争，第一个线程设置一个标志，用来表明数据已经准备就绪，并且第二个线程在这个标志设置前不能读取数据。下面的程序清单就是这样的情况。

> 清单5.2 不同线程对数据的读写
>
> ```cpp
> #include <vector>
> #include <atomic>
> #include <iostream>
> 
> std::vector<int> data;
> std::atomic<bool> data_ready(false);
> 
> void reader_thread()
> {
>   while(!data_ready.load())  // 1
>   {
>     std::this_thread::sleep(std::milliseconds(1));
>   }
>   std::cout<<"The answer="<<data[0]<<"\m";  // 2
> }
> void writer_thread()
> {
>   data.push_back(42);  // 3
>   data_ready=true;  // 4
> }
> ```
>
> 先把等待数据的低效循环①放在一边（你需要这个循环，否则想要在线程间共享数据就是不切实际的：数据的每一项都必须是原子的）。你已经知道，当非原子读②和写③对同一数据结构进行无序访问时，将会导致未定义行为的发生，因此这个循环就是确保访问循序被严格的遵守的。
>
> **强制访问顺序是由对`std::atomic<bool>`类型的data_ready变量进行操作完成的**；这些操作通过“[**先行发生**](http://en.wikipedia.org/wiki/Happened-before)”(*happens-before*)和“**同步发生**”(*synchronizes-with*)确定必要的顺序。写入数据③的操作，在写入data_ready标志④的操作前发生，并且读取标志①发生在读取数据②之前。当data_ready①为true，写操作就会与读操作同步，建立一个“先行发生”关系。因为“先行发生”是可传递的，所以读取数据③先行于写入标志④，这两个行为又先行于读取标志的操作①，之前的操作都先行于读取数据②，这样你就拥有了强制顺序：写入数据先行于读取数据。
>
> <img src="/home/suyu/.config/Typora/typora-user-images/image-20230315193801202.png" alt="image-20230315193801202" style="zoom:50%;" />

### 同步发生

“同步发生”的基本想法是：在变量x进行适当标记的原子写操作W，同步与对x进行适当标记的原子读操作，读取的是W操作写入的内容；或是在W之后，同一线程上的原子写操作对x写入的值；亦或是任意线程对x的一系列原子读-改-写操作。这里，第一个线程读取到的值是W操作写入的(详见5.3.4节)。

先将“适当的标记”放在一边，因为所有对原子类型的操作，默认都是适当标记的。这实际上就是：如果线程A存储了一个值，并且线程B读取了这个值，线程A的存储操作与线程B的载入操作就是同步发生的关系，如上图。

内存排序的各种选项和它们如何与同步发生的关系，将会在5.3.3节中讨论。

让我们先退一步，再来看一下“先行发生”关系。

### 先行发生

“先行发生”关系是一个程序中，基本构建块的操作顺序。它指定了某个操作去影响另一个操作。对于单线程来说，就简单了：当一个操作排在另一个之后，那么这个操作就是先行执行的。这意味着，如果源码中操作A发生在操作B之前，那么A就先行与B发生。你可以回看清单5.2：对data的写入③先于对data_ready④的写入。如果操作在同时发生，因为操作间无序执行，通常情况下，它们就没有先行关系了。这就是另一种排序未被指定的情况。下面的程序会输出“1，2”或“2，1”，因为两个get_num()的执行顺序未被指定。

> 清单5.3 对于参数中的函数调用顺序是未指定顺序的
>
> ```cpp
> #include <iostream>
> void foo(int a,int b)
> {
>   std::cout<<a<<”,”<<b<<std::endl;
> }
> int get_num()
> {
>   static int i=0;
>   return ++i;
> }
> int main()
> {
>   foo(get_num(),get_num());  // 无序调用get_num()
> }
> ```
>
> 这种情况下，操作在单一声明中是可测序的，例如，逗号操作符的使用，或一个表达式的结果作为一个参数传给另一个表达式。但在通常情况下，操作在单一声明中是不可测序的，所以对其无法先行安排顺序(也就没有先行发生了)。当然，所有操作在一个声明中先行与在下一个声明中的操作。

如果操作A在线程上，并且线程先行与另一线程上的操作B，那么A就先行于B。这也没什么：你只是添加了一个新关系(线程间的先行)，但当你正在编写多线程程序时，是就这是一个至关重要的关系。

从基本层面上讲，线程间的先行比较简单，并且依赖与同步关系(详见5.3.1节)：如果操作A在一个线程上，与另一个线程上的操作B同步，那么A就线程间先行与B。这同样是一个传递关系：如果A线程间先行与B，并且B线程间先行与C，那么A就线程间先行与C。**两者的结合，意味着当你对数据进行一系列修改(单线程)时，为线程后续执行C，只需要对可见数据进行一次同步**

**这些是线程间强制排序操作的关键规则**，也是让清单5.2正常运行的因素。并在数据依赖上有一些细微的差别，你马上就会看到。为了让你理解这些差别，需要讲述一下原子操作使用的内存排序标签，以及这些标签和同步发生之间的联系。

### 原子操作的内存顺序

这里有六个内存序列选项可应用于对原子类型的操作：

- 获取-释放序列

  memory_order_relaxed

  memory_order_consume

  memory_order_acquire

  memory_order_release

- 自由序列

  memory_order_acq_rel

- 排序一致序列(*sequentially consistent*)

  memory_order_seq_cst

这些不同的内存序列模型，在不同的CPU架构下，功耗是不一样的。

例如，基于处理器架构的可视化精细操作的系统，比起其他系统，添加的同步指令可被排序一致序列使用(在获取-释放序列和自由序列之前)，或被获取-释放序列调用(在自由序列之前)。如果这些系统有多个处理器，这些额外添加的同步指令可能会消耗大量的时间，从而降低系统整体的性能。

另一方面，**CPU使用的是x86或x86-64架构**(例如，使用Intel或AMD处理器的台式电脑)，使用这种架构的CPU**不需要任何对获取-释放序列添加额外的指令**(没有保证原子性的必要了)，并且，即使是排序一致序列，对于加载操作也不需要任何特殊的处理，不过在进行存储时，有点额外的消耗。

#### 排序一致序列

默认序列命名为“排序一致”(*sequentially cons*)，是因为它**意味着，程序中的行为从任意角度去看，序列顺序都保持一致**。如果原子类型实例上的所有操作都是序列一致的，那么一个多线程程序的行为，就以某种特殊的排序执行，好像单线程那样。这是目前来看，最容易理解的内存序列，这也就是将其设置为默认的原因：所有线程都必须了解，不同的操作也遵守相同的顺序。因为其简单的行为，可以使用原子变量进行编写。通过不同的线程，你可以写出所有序列上可能的操作，这样就可以消除那些不一致，以及验证你代码的行为是否与预期相符。这也就意味着，所有操作都不能重排序；如果你的代码，在一个线程中，**将一个操作放在另一个操作前面**，那么这个顺序就必须让其他所有的线程所了解。

> 在一个多核若排序的机器上，它会加强对性能的惩罚，因为整个序列中的操作都必须在多个处理器上保持一致，可能需要对处理器间的同步操作进行扩展(代价很昂贵！)。即便如此，一些处理器架构(比如通用x86和x86-64架构)就提供了相对廉价的序列一致，所以**你需要考虑使用序列一致对性能的影响，这就需要你去查阅你目标处理器的架构文档**，进行更多的了解。

以下清单展示了序列一致的行为

> 清单5.4 全序——序列一致
>
> ```cpp
> #include <atomic>
> #include <thread>
> #include <assert.h>
> 
> std::atomic<bool> x,y;
> std::atomic<int> z;
> 
> void write_x()
> {
>   x.store(true,std::memory_order_seq_cst);  // 1
> }
> 
> void write_y()
> {
>   y.store(true,std::memory_order_seq_cst);  // 2
> }
> void read_x_then_y()
> {
>   while(!x.load(std::memory_order_seq_cst));
>   if(y.load(std::memory_order_seq_cst))  // 3
>     ++z;
> }
> void read_y_then_x()
> {
>   while(!y.load(std::memory_order_seq_cst));
>   if(x.load(std::memory_order_seq_cst))  // 4
>     ++z;
> }
> int main()
> {
>   x=false;
>   y=false;
>   z=0;
>   std::thread a(write_x);
>   std::thread b(write_y);
>   std::thread c(read_x_then_y);
>   std::thread d(read_y_then_x);
>   a.join();
>   b.join();
>   c.join();
>   d.join();
>   assert(z.load()!=0);  // 5
> }
> ```
>
> 

#### 获取-释放序列

这个序列是自由序列(*relaxed ordering*)的加强版；虽然操作依旧没有统一的顺序，但是在这个序列引入了同步。在这种序列模型中，**原子加载就是“获取”(*acquire*)操作(memory_order_acquire)，原子存储就是“释放”操作(memory_order_release)**，原子读-改-写操作(例如`fetch_add()`或`exchange()`)在这里，不是“获取”，就是“释放”，**或者两者兼有的操作(memory_order_acq_rel)**。这里，同步在线程释放和获取间，是成对的(*pairwise*)。释放操作与获取操作同步，这样就能读取已写入的值。这意味着不同线程看到的序列虽还是不同，但这些序列都是受限的。下面列表中是使用获取-释放序列(而非序列一致方式)，对清单5.4的一次重写。

> 清单5.7 获取-释放不意味着统一操作顺序
>
> ```cpp
> #include <atomic>
> #include <thread>
> #include <assert.h>
> 
> std::atomic<bool> x,y;
> std::atomic<int> z;
> void write_x()
> {
>   x.store(true,std::memory_order_release);
> }
> void write_y()
> {
>   y.store(true,std::memory_order_release);
> }
> void read_x_then_y()
> {
>   while(!x.load(std::memory_order_acquire));
>   if(y.load(std::memory_order_acquire))  // 1
>     ++z;
> }
> void read_y_then_x()
> {
>   while(!y.load(std::memory_order_acquire));
>   if(x.load(std::memory_order_acquire))
>     ++z;
> }
> int main()
> {
>   x=false;
>   y=false;
>   z=0;
>   std::thread a(write_x);
>   std::thread b(write_y);
>   std::thread c(read_x_then_y);
>   std::thread d(read_y_then_x);
>   a.join();
>   b.join();
>   c.join();
>   d.join();
>   assert(z.load()!=0); // 3
> }
> ```

在这个例子中断言③可能会触发(就如同自由排序那样)，因为可能在加载x②和y③的时候，读取到的是false。因为x和y是由不同线程写入，所以序列中的每一次释放到获取都不会影响到其他线程的操作。

![image-20230317165325800](/home/suyu/.config/Typora/typora-user-images/image-20230317165325800.png)

为了了解获取-释放序列有什么优点，你需要考虑将两次存储由一个线程来完成，就像清单5.5那样。当你需要使用memory_order_release改变y中的存储，并且使用memory_order_acquire来加载y中的值，就像下面程序清单所做的那样，而后，就会影响到序列中对x的操作。

> 清单5.8 获取-释放操作会影响序列中的释放操作
>
> ```cpp
> #include <atomic>
> #include <thread>
> #include <assert.h>
> 
> std::atomic<bool> x,y;
> std::atomic<int> z;
> 
> void write_x_then_y()
> {
>   x.store(true,std::memory_order_relaxed);  // 1 自旋，等待y被设置为true
>   y.store(true,std::memory_order_release);  // 2
> }
> void read_y_then_x()
> {
>   while(!y.load(std::memory_order_acquire));  // 3
>   if(x.load(std::memory_order_relaxed))  // 4
>     ++z;
> }
> int main()
> {
>   x=false;
>   y=false;
>   z=0;
>   std::thread a(write_x_then_y);
>   std::thread b(read_y_then_x);
>   a.join();
>   b.join();
>   assert(z.load()!=0);  // 5
> }
> ```
>
> 读取y③时会得到true，和存储时写入的一样②。**因为存储使用的是memory_order_release，读取使用的是memory_order_acquire，存储就与读取就同步了。**因为这两个操作是由同一个线程完成的，所以存储x①先行与加载y②。对y的存储同步与对y的加载，存储x也就先行于对y的加载，并且扩展先行与x的读取。因此，**加载x的值必为true**，并且断言⑤不会触发。如果对于y的加载不是在while循环中，那么情况可能就会有所不同；**加载y的时候可能会读取到false**，在这种情况下对于读取到的x是什么值，就没有要求了。***为了保证同步，加载和释放操作必须成对。所以，无论有何影响，释放操作存储的值，必须要让获取操作看到***。当存储如②或加载如③，都是一个释放操作时，对x的访问就无序了，也就无法保证④处读到的是true，并且还会触发断言。

当你回看5.3.2节中对“线程间先行”的定义，一个很重要的特性就是它的传递：当A线程间先行于B，并且B线程间先行于C，那么A就线程间先行于C。**这就意味着，获取-释放序列可以在若干线程间使用同步数据，甚至可以在“中间”线程接触到这些数据前，使用这些数据。**

#### 与同步传递相关的获取-释放序列

为了考虑传递顺序，你至少需要三个线程。

- 第一个线程用来修改共享变量，并且对其中一个做“存储-释放”处理。
- 第二个线程使用“加载-获取”读取由“存储-释放”操作过的变量，并且再对第二个变量进行“存储-释放”操作。
- 第三个线程通过“加载-获取”读取第二个共享变量。提供“加载-获取”操作，来读取被“存储-释放”操作写入的值，是为了保证同步关系，这里即便是中间线程没有对共享变量做任何操作，第三个线程也可以读取被第一个线程操作过的变量。下面的代码可以用来描述这样的场景。

> 清单5.9 使用获取和释放顺序进行同步传递
>
> ```cpp
> std::atomic<int> data[5];
> std::atomic<bool> sync1(false),sync2(false);
> 
> void thread_1()
> {
>   data[0].store(42,std::memory_order_relaxed);
>   data[1].store(97,std::memory_order_relaxed);
>   data[2].store(17,std::memory_order_relaxed);
>   data[3].store(-141,std::memory_order_relaxed);
>   data[4].store(2003,std::memory_order_relaxed);
>   sync1.store(true,std::memory_order_release);  // 1.设置sync1
> }
> 
> void thread_2()
> {
>   while(!sync1.load(std::memory_order_acquire));  // 2.直到sync1设置后，循环结束
>   sync2.store(true,std::memory_order_release);  // 3.设置sync2
> }
> void thread_3()
> {
>   while(!sync2.load(std::memory_order_acquire));   // 4.直到sync1设置后，循环结束
>   assert(data[0].load(std::memory_order_relaxed)==42);
>   assert(data[1].load(std::memory_order_relaxed)==97);
>   assert(data[2].load(std::memory_order_relaxed)==17);
>   assert(data[3].load(std::memory_order_relaxed)==-141);
>   assert(data[4].load(std::memory_order_relaxed)==2003);
> }
> ```
>
> 尽管thread_2只接触到变量syn1②和sync2③，不过这对于thread_1和thread_3的同步就足够了，这就能保证断言不会触发。首先，thread_1将数据存储到data中先行与存储sync1①（它们在同一个线程内）。因为加载sync1①的是一个while循环，它最终会看到thread_1存储的值(是从“释放-获取”对的后半对获取)。因此，对于sync1的存储先行与最终对于sync1的加载(在while循环中)。thread_3的加载操作④，位于存储sync2③操作的前面(也就是先行)。存储sync2③因此先行于thread_3的加载④，加载又先行与存储sync2③，存储sync2又先行与加载sync2④，加载syn2又先行与加载data。因此，thread_1存储数据到data的操作先行于thread_3中对data的加载，并且保证断言都不会触发。

在这个例子中，你可以**将sync1和sync2，通过在thread_2中使用“读-改-写”操作(memory_order_acq_rel)，将其合并成一个独立的变量**。其中会使用compare_exchange_strong()来保证thread_1对变量只进行一次更新：

```cpp
std::atomic<int> sync(0);
void thread_1()
{
  // ...
  sync.store(1,std::memory_order_release);
}

void thread_2()
{
  int expected=1;
  while(!sync.compare_exchange_strong(expected,2,
              std::memory_order_acq_rel))
    expected=1;
}

void thread_3()
{
  while(sync.load(std::memory_order_acquire)<2);
  // ...
}
```

> 如果你使用“读-改-写”操作，选择语义就很重要了。在这个例子中，**你想要同时进行获取和释放的语义，所以memory_order_acq_rel是一个合适的选择**，但你也可以使用其他序列。使用memory_order_acquire语义的fetch_sub是不会和任何东西同步的，即使它存储了一个值，这是因为其没有释放操作。同样的，使用memory_order_release语义的fetch_or也不会和任何存储操作进行同步，因为对于fetch_or的读取，并不是一个获取操作。使用memory_order_acq_rel语义的“读-改-写”操作，每一个动作都包含获取和释放操作，所以可以和之前的存储操作进行同步，并且可以对随后的加载操作进行同步，就像上面例子中那样。

#### 获取-释放序列和memory_order_consume的数据相关性

memory_order_consume是“获取-释放”序列模型的一部分，但memory_order_consume很特别：它完全依赖于数据，并且其展示了与线程间先行关系(可见5.3.2节)的不同之处。

这里有两种新关系用来处理数据依赖：前序依赖(*dependency-ordered-before*)和携带依赖(*carries-a-dependency-to*)。

当其不影响线程间的先行关系时，对于同步来说，这并未带来任何的好处，但是它做到：当A前序依赖B，那么A线程间也前序依赖B。

这种内存序列的一个**很重要使用方式，是在原子操作载入指向数据的指针时**。当使用memory_order_consume作为加载语义，并且memory_order_release作为之前的存储语义，你要保证指针指向的值是已同步的，并且不需要对其他任何非独立数据施加任何同步要求。下面的代码就展示了这么一个场景。

> 清单5.10 使用`std::memroy_order_consume`同步数据
>
> ```cpp
> struct X
> {
> int i;
> std::string s;
> };
> 
> std::atomic<X*> p;
> std::atomic<int> a;
> 
> void create_x()
> {
>   X* x=new X;
>   x->i=42;
>   x->s="hello";
>   a.store(99,std::memory_order_relaxed);  // 1
>   p.store(x,std::memory_order_release);  // 2
> }
> 
> void use_x()
> {
>   X* x;
>   while(!(x=p.load(std::memory_order_consume)))  // 3
>     std::this_thread::sleep(std::chrono::microseconds(1));
>   assert(x->i==42);  // 4
>   assert(x->s=="hello");  // 5
>   assert(a.load(std::memory_order_relaxed)==99);  // 6
> }
> 
> int main()
> {
>   std::thread t1(create_x);
>   std::thread t2(use_x);
>   t1.join();
>   t2.join();
> }
> ```
>
> 对a的存储①在存储p②之前，并且存储p的操作标记为memory_order_release，加载p的操作标记为memory_order_consume，这就意味着**存储p仅先行那些需要加载p的操作**。同样，也意味着X结构体中数据成员所在的断言语句④⑤，不会被触发，这是因为对x变量操作的表达式对加载p的操作携带有依赖。另一方面，对于加载变量a的断言就不能确定是否会被触发；这个操作并不依赖于p的加载操作，所以这里没法保证数据已经被读取。当然，这个情况也是很明显的，因为这个操作被标记为memory_order_relaxed。

有时，你不想为携带依赖增加其他的开销。你想让编译器在寄存器中缓存这些值，以及优化重排序操作代码，而不是对这些依赖大惊小怪。这种情况下，你**可以使用`std::kill_dependecy()`来显式打破依赖链**。`std::kill_dependency()`是一个简单的函数模板，其会复制提供的参数给返回值，但是依旧会打破依赖链。例如，当你拥有一个全局的只读数组，当其他线程对数组索引进行检索时，你使用的是`std::memory_order_consume`，那么你可以使用`std::kill_dependency()`让编译器知道这里不需要重新读取该数组的内容，就像下面的例子一样：

```cpp
int global_data[]={ … };
std::atomic<int> index;

void f()
{
  int i=index.load(std::memory_order_consume);
  do_something_with(global_data[std::kill_dependency(i)]);
}
```

你必须记住，这是为了优化，所以这种方式必须谨慎使用，并且需要性能数据证明其存在的意义。

###  释放队列与同步

……

### 栅栏

栅栏操作会对内存序列进行约束，使其无法对任何数据进行修改，典型的做法是与使用memory_order_relaxed约束序的原子操作一起使用。栅栏属于全局操作，执行栅栏操作可以影响到在线程中的其他原子操作。因为这类操作就像画了一条任何代码都无法跨越的线一样，所以栅栏操作通常也被称为“内存栅栏”(*memory barriers*)。

> 清单5.12 栅栏可以让自由操作变的有序
>
> ```cpp
> #include <atomic>
> #include <thread>
> #include <assert.h>
> 
> std::atomic<bool> x,y;
> std::atomic<int> z;
> 
> void write_x_then_y()
> {
>   x.store(true,std::memory_order_relaxed);  // 1
>   std::atomic_thread_fence(std::memory_order_release);  // 2
>   y.store(true,std::memory_order_relaxed);  // 3
> }
> 
> void read_y_then_x()
> {
>   while(!y.load(std::memory_order_relaxed));  // 4
>   std::atomic_thread_fence(std::memory_order_acquire);  // 5
>   if(x.load(std::memory_order_relaxed))  // 6
>     ++z;
> }
> 
> int main()
> {
>   x=false;
>   y=false;
>   z=0;
>   std::thread a(write_x_then_y);
>   std::thread b(read_y_then_x);
>   a.join();
>   b.join();
>   assert(z.load()!=0);  // 7
> }
> ```
>
> 释放栅栏②与获取栅栏⑤同步，这是因为加载y的操作④读取的是在③处存储的值。所以，在①处存储x先行于⑥处加载x，最后x读取出来必为true，并且断言不会被触发⑦。原先不带栅栏的存储和加载x都是无序的，并且断言是可能会触发的。需要注意的是，这两个栅栏都是必要的：你需要在一个线程中进行释放，然后在另一个线程中进行获取，这样才能构建出同步关系。
>
> 在这个例子中，如果存储y的操作③标记为memory_order_release，而非memory_order_relaxed的话，释放栅栏②也会对这个操作产生影响。同样的，当加载y的操作④标记为memory_order_acquire时，获取栅栏⑤也会对之产生影响。

使用栅栏的一般想法是：当一个获取操作能看到释放栅栏操作后的存储结果，那么这个栅栏就与获取操作同步；并且，当加载操作在获取栅栏操作前，看到一个释放操作的结果，那么这个释放操作同步于获取栅栏。当然，你也可以使用双边栅栏操作，举一个简单的例子，**当一个加载操作在获取栅栏前，看到一个值有存储操作写入，且这个存储操作发生在释放栅栏后，那么释放栅栏与获取栅栏是同步的。**

栅栏同步依赖于读取/写入的操作发生于栅栏之前/后，但是这里有一点很重要：同步点，就是栅栏本身。当你执行清单5.12中的write_x_then_y，并且在栅栏操作之后对x进行写入，就像下面的代码一样。这里，触发断言的条件就不保证一定为true了，尽管写入x的操作在写入y的操作之前发生。

```cpp
void write_x_then_y()
{
  std::atomic_thread_fence(std::memory_order_release);
  x.store(true,std::memory_order_relaxed);
  y.store(true,std::memory_order_relaxed);
}
```

这里里的两个操作，就不会被栅栏分开，并且也不再有序。只有当栅栏出现在存储x和存储y操作之间，这个顺序是硬性的。当然，栅栏是否存在不会影响任何拥有先行关系的执行序列，这种情况是因为一些其他原子操作。

### 原子操作对非原子的操作排序

当你使用一个普通的非原子bool类型来替换清单5.12中的x(就如同你下面看到的代码)，行为和替换前完全一样。

> 清单5.13 使用非原子操作执行序列
>
> ```cpp
> #include <atomic>
> #include <thread>
> #include <assert.h>
> 
> bool x=false;  // x现在是一个非原子变量
> std::atomic<bool> y;
> std::atomic<int> z;
> 
> void write_x_then_y()
> {
>   x=true;  // 1 在栅栏前存储x
>   std::atomic_thread_fence(std::memory_order_release);
>   y.store(true,std::memory_order_relaxed);  // 2 在栅栏后存储y
> }
> 
> void read_y_then_x()
> {
>   while(!y.load(std::memory_order_relaxed));  // 3 在#2写入前，持续等待
>   std::atomic_thread_fence(std::memory_order_acquire);
>   if(x)  // 4 这里读取到的值，是#1中写入
>     ++z;
> }
> int main()
> {
>   x=false;
>   y=false;
>   z=0;
>   std::thread a(write_x_then_y);
>   std::thread b(read_y_then_x);
>   a.join();
>   b.join();
>   assert(z.load()!=0);  // 5 断言将不会触发
> }
> ```
>
> 栅栏仍然为存储x①和存储y②，还有加载y③和加载x④提供一个执行序列，并且这里仍然有一个先行关系，在存储x和加载x之间，所以断言⑤不会被触发。②中的存储和③中对y的加载，都必须是原子操作；否则，将会在y上产生条件竞争，不过一旦读取线程看到存储到y的操作，栅栏将会对x执行有序的操作。这个执行顺序意味着，x上不存在条件竞争，即使它被另外的线程修改或被其他线程读取。

对于C++标准库的高阶同步工具来说，这些都是基本，例如互斥量和条件变量。可以回看它们都是如何工作的，可以对清单5.1中简单的自旋锁展开更加深入的思考。

使用`std::memory_order_acquire`序列的lock()操作是在flag.test_and_set()上的一个循环，并且使用`std::memory_order_release`序列的unlock()调用flag.clear()。当第一个线程调用lock()时，标志最初是没有的，所以第一次调用test_and_set()将会设置标志，并且返回false，表示线程现在已锁，并且结束循环。之后，线程可以自由的修改由互斥量保护的数据。这时，任何想要调用lock()的线程，将会看到已设置的标志，而后会被test_and_set()中的循环所阻塞。

当线程带锁线程完成对保护数据的修改，它会调用unlock()，相当于调用带有`std::memory_order_release`语义的flag.clear()。这与随后其他线程访问flag.test_and_set()时调用lock()同步(见5.3.1节)，这是因为对lock()的调用带有`std::memory_order_acquire`语义。因为对于保护数据的修改，必须先于unlock()的调用，所以修改“先行”于unlock()，并且还“先行”于之后第二个线程对lock()的调用(因为同步关系是在unlock()和lock()中产生的)，还“先行”于当第二个线程获取锁后，对保护数据的任何访问。

虽然，其他互斥量的内部实现不尽相同，不过基本原理都是一样的:在某一内存位置上，lock()作为一个获取操作存在，在同样的位置上unlock()作为一个释放操作存在。

